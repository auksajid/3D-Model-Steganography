{"cells":[{"cell_type":"markdown","source":["Embedding Process in 3D Object RiggedHand"],"metadata":{"id":"t0Q6XtxgM30r"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"RgfQzI6PLc4w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736790539471,"user_tz":-300,"elapsed":9389,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"outputId":"4d890ea0-c4c2-4964-de34-6e5e6acd71ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pycryptodome\n","  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pycryptodome\n","Successfully installed pycryptodome-3.21.0\n","Collecting trimesh\n","  Downloading trimesh-4.5.3-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from trimesh) (1.26.4)\n","Downloading trimesh-4.5.3-py3-none-any.whl (704 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.8/704.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: trimesh\n","Successfully installed trimesh-4.5.3\n"]}],"source":["#!pip install pycryptodome\n","#!pip install trimesh\n","import numpy as np\n","from Crypto.Cipher import AES\n","from Crypto.Util.Padding import pad, unpad\n","import hashlib\n","import secrets\n","import struct\n","import trimesh\n","import scipy.spatial as spatial\n","\n","class SecureFaceSteganography:\n","    def __init__(self):\n","        # ... (other code)\n","        self.LANDMARK_REGIONS = {\n","            'forehead': [(0.2, 0.8, 0.5), (0.8, 0.8, 0.5)],  # Wider bounding box\n","            'cheeks': [(0.1, 0.5, 0.5), (0.9, 0.5, 0.5)],  # Wider bounding box\n","            'jaw': [(0.2, 0.2, 0.5), (0.8, 0.2, 0.5)],  # Wider bounding box\n","            'nose': [(0.4, 0.6, 0.5), (0.6, 0.6, 0.5)],  # Added nose region\n","            'chin': [(0.5, 0.1, 0.5)]  #chin region\n","        }\n","        # Define SALT_SIZE and BLOCK_SIZE in the __init__ method\n","        self.SALT_SIZE = 16  # 128 bits for salt\n","        self.BLOCK_SIZE = 16 # 128 bits for block size\n","        self.distributed_landmarks = None  # Initialize distributed_landmarks\n","\n","    def load_face_model(self, file_path):\n","        \"\"\"Load 3D face model and prepare it for steganography\"\"\"\n","        try:\n","            loaded_data = trimesh.load(file_path)\n","            # Check if loaded_data is a Scene and extract the first mesh if it is\n","            if isinstance(loaded_data, trimesh.Scene):\n","                mesh = next(iter(loaded_data.geometry.values())) # Get the first mesh from the scene\n","            else:\n","                mesh = loaded_data\n","\n","            return {\n","                'vertices': np.array(mesh.vertices),\n","                'faces': np.array(mesh.faces),\n","                'normals': np.array(mesh.vertex_normals)\n","            }\n","        except Exception as e:\n","            raise ValueError(f\"Error loading face model: {str(e)}\")\n","\n","    def identify_landmark_vertices(self, vertices, landmark_regions=None):\n","        if landmark_regions is None:\n","            landmark_regions = self.LANDMARK_REGIONS\n","\n","        # Use stored landmarks if available, otherwise generate\n","        if self.distributed_landmarks is None:\n","            num_landmarks = min(1000, len(vertices))\n","            self.distributed_landmarks = np.random.choice(len(vertices), num_landmarks, replace=False)\n","\n","        return sorted(self.distributed_landmarks)  # Return stored landmarks\n","\n","    def compute_vertex_importance(self, vertices, faces, normals):\n","        \"\"\"Compute vertex importance based on geometric features\"\"\"\n","        importance = np.zeros(len(vertices))\n","\n","        # Calculate curvature (simplified)\n","        for i, vertex in enumerate(vertices):\n","            # Find connected vertices\n","            connected = faces[np.any(faces == i, axis=1)]\n","            connected = np.unique(connected.flatten())\n","            connected = connected[connected != i]\n","\n","            # Calculate local curvature\n","            if len(connected) > 0:\n","                connected_vertices = vertices[connected]\n","                mean_position = np.mean(connected_vertices, axis=0)\n","                displacement = np.linalg.norm(vertex - mean_position)\n","                importance[i] = displacement\n","\n","        return importance\n","\n","    def generate_passphrase(self, length=32):\n","        \"\"\"Generate a cryptographically secure random passphrase\"\"\"\n","        charset = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&*\"\n","        return ''.join(secrets.choice(charset) for _ in range(length))\n","\n","    def derive_key(self, passphrase, salt):\n","        \"\"\"Derive encryption key using SHA-256 with salt\"\"\"\n","        key_material = hashlib.sha256()\n","        key_material.update(passphrase.encode('utf-8'))\n","        key_material.update(salt)\n","        return key_material.digest()\n","\n","    def encrypt_message(self, message, passphrase):\n","        \"\"\"Encrypt a message using AES-128-CBC with secure key derivation\"\"\"\n","        salt = secrets.token_bytes(self.SALT_SIZE)\n","        key = self.derive_key(passphrase, salt)\n","        iv = secrets.token_bytes(self.BLOCK_SIZE)\n","\n","        cipher = AES.new(key, AES.MODE_CBC, iv)\n","        padded_data = pad(message.encode('utf-8'), self.BLOCK_SIZE)\n","        ciphertext = cipher.encrypt(padded_data)\n","\n","        return salt + iv + ciphertext\n","\n","    def decrypt_message(self, encrypted_data, passphrase):\n","        \"\"\"Decrypt a message using AES-128-CBC\"\"\"\n","        salt = encrypted_data[:self.SALT_SIZE]\n","        iv = encrypted_data[self.SALT_SIZE:self.SALT_SIZE + self.BLOCK_SIZE]\n","        ciphertext = encrypted_data[self.SALT_SIZE + self.BLOCK_SIZE:]\n","\n","        key = self.derive_key(passphrase, salt)\n","        cipher = AES.new(key, AES.MODE_CBC, iv)\n","\n","        # Attempt to decrypt. Handle potential padding errors\n","        try:\n","            padded_message = cipher.decrypt(ciphertext)\n","            return unpad(padded_message, self.BLOCK_SIZE).decode('utf-8')\n","        except ValueError:\n","            print(\"Warning: Decryption failed. Possible data corruption or incorrect passphrase.\")\n","            return None  # or raise a more specific exception\n","\n","\n","    def embed_in_face_model(self, face_model, encrypted_data):\n","        \"\"\"Embed encrypted data in 3D face model using geometric features\"\"\"\n","        vertices = face_model['vertices'].copy()\n","        faces = face_model['faces']\n","        normals = face_model['normals']\n","\n","        # Get landmarks and importance metrics\n","        landmark_vertices = self.identify_landmark_vertices(vertices)\n","        importance = self.compute_vertex_importance(vertices, faces, normals)\n","\n","        # Convert encrypted data to bit array\n","        bit_array = ''.join(format(byte, '08b') for byte in encrypted_data)\n","\n","        # Check if the message is too large\n","        if len(bit_array) > len(landmark_vertices):\n","            raise ValueError(f\"Message too large for this face model. Message bits: {len(bit_array)}, Available vertices: {len(landmark_vertices)}\")\n","\n","        # Embed data in vertices near landmarks using rounding and a larger scale factor\n","        for i, bit in enumerate(bit_array):\n","            vertex_idx = landmark_vertices[i]\n","            scale_factor = 0.001 * (1 - importance[vertex_idx])  # Significantly increased scale_factor\n","\n","            # Apply rounding to the modification\n","            modification = round(float(bit) * scale_factor, 6)  # Round to 6 decimal places\n","\n","            vertices[vertex_idx] += modification * normals[vertex_idx]\n","\n","        face_model['vertices'] = vertices\n","        return face_model\n","\n","    def extract_from_face_model(self, face_model, original_model, message_length):\n","        \"\"\"Extract encrypted data from modified 3D face model\"\"\"\n","        modified_vertices = face_model['vertices']\n","        original_vertices = original_model['vertices']\n","        landmark_vertices = self.identify_landmark_vertices(original_vertices)\n","\n","        bits = []\n","        for i in range(message_length * 8):  # Iterate over the expected number of bits\n","            if i >= len(landmark_vertices):\n","                print(f\"Warning: Not enough landmark vertices to extract the full message. Extracted {i} bits, expected {message_length * 8} bits.\")\n","                break  # Stop if we run out of landmark vertices\n","            vertex_idx = landmark_vertices[i]\n","\n","            # Compare modified vertex with original\n","            diff = modified_vertices[vertex_idx] - original_vertices[vertex_idx]\n","            # Extract bit based on vertex displacement using a tolerance\n","\n","            extracted_bit = np.dot(diff, original_model['normals'][vertex_idx]) #Using original normals\n","\n","            #Using tolerance instead of direct comparison with 0\n","            bit = '1' if extracted_bit > 1e-6 else '0'\n","            bits.append(bit)\n","\n","        # Convert bits back to bytes\n","        extracted_data = bytes(\n","            int(''.join(bits[i:i + 8]), 2) for i in range(0, len(bits), 8)\n","        )\n","\n","        return extracted_data\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QpXnlmOzLjqq","outputId":"9a511ee2-0097-4387-cff9-4453e4e61602","executionInfo":{"status":"ok","timestamp":1736790553139,"user_tz":-300,"elapsed":621,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Generated passphrase: An9X*!p9vvO8IF!25Pe8o8wUuaq8hqlz\n","Original message: short\n","Decrypted message: short\n"]}],"source":["def main():\n","    # Initialize steganography system\n","    stego = SecureFaceSteganography()\n","\n","    # Load 3D face model (example path)\n","    face_model = stego.load_face_model('/content/drive/MyDrive/OutputPaper2/RiggedHand.obj')\n","    original_model = {key: value.copy() for key, value in face_model.items()}\n","\n","    # Generate secure passphrase\n","    passphrase = stego.generate_passphrase()\n","    print(f\"Generated passphrase: {passphrase}\")\n","\n","    # Message to hide - Reduced length to fit within the model's capacity\n","    secret_message = \"short\"\n","\n","    # Encrypt the message\n","    encrypted_data = stego.encrypt_message(secret_message, passphrase)\n","\n","    # Embed encrypted data in face model\n","    modified_model = stego.embed_in_face_model(face_model, encrypted_data)\n","\n","    # Extract and decrypt\n","    extracted_data = stego.extract_from_face_model(\n","        modified_model, original_model, len(encrypted_data)\n","    )\n","    decrypted_message = stego.decrypt_message(extracted_data, passphrase)\n","\n","    print(f\"Original message: {secret_message}\")\n","    print(f\"Decrypted message: {decrypted_message}\")\n","\n","    # Save modified model\n","    mesh = trimesh.Trimesh(\n","        vertices=modified_model['vertices'],\n","        faces=modified_model['faces']\n","    )\n","    mesh.export('/content/drive/MyDrive/OutputPaper2/modified_RiggedHand.obj')\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","source":["Evaluation RiggedHand"],"metadata":{"id":"lU1xKPixMw5r"}},{"cell_type":"code","source":["#!pip install 'pyglet<2'\n","#!apt-get install -y libglu1-mesa-dev"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QCvHsjMkDQzU","executionInfo":{"status":"ok","timestamp":1736786172128,"user_tz":-300,"elapsed":9655,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"outputId":"cffc28c8-0f8c-49b9-880d-c5cec90cd4c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyglet<2 in /usr/local/lib/python3.10/dist-packages (1.5.31)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libglu1-mesa-dev is already the newest version (9.0.2-1).\n","0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"]}]},{"source":["#!pip install pyglet\n","#!pip install pyglet<2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error\n","import trimesh\n","from scipy.stats import wasserstein_distance\n","from skimage.metrics import structural_similarity\n","import math\n","from scipy.spatial import KDTree\n","import os\n","\n","class Stego3DEvaluator:\n","    def __init__(self):\n","        \"\"\"Initialize the 3D steganography evaluator\"\"\"\n","        self.metrics = {}\n","\n","    def preprocess_models(self, original_mesh, stego_mesh):\n","        \"\"\"Preprocess and align models to ensure compatibility\"\"\"\n","        # Center both meshes\n","        original_mesh.vertices -= original_mesh.vertices.mean(axis=0)\n","        stego_mesh.vertices -= stego_mesh.vertices.mean(axis=0)\n","\n","        # Scale to unit cube\n","        original_scale = np.max(np.abs(original_mesh.vertices))\n","        stego_scale = np.max(np.abs(stego_mesh.vertices))\n","\n","        original_mesh.vertices /= original_scale\n","        stego_mesh.vertices /= stego_scale\n","\n","        return original_mesh, stego_mesh\n","\n","    def align_vertices(self, original_vertices, stego_vertices):\n","        \"\"\"Align vertices between models using nearest neighbor matching\"\"\"\n","        # Build KD-tree for faster nearest neighbor search\n","        tree = KDTree(original_vertices)\n","\n","        # Find nearest neighbors for each stego vertex\n","        distances, indices = tree.query(stego_vertices)\n","\n","        # Create aligned vertex arrays\n","        aligned_original = original_vertices[indices]\n","        aligned_stego = stego_vertices\n","\n","        return aligned_original, aligned_stego, distances\n","\n","    def load_models(self, original_path, stego_path, align=True):\n","        \"\"\"Load and preprocess original and stego 3D models\"\"\"\n","        try:\n","            # Load meshes\n","            original_mesh = trimesh.load(original_path)\n","            stego_mesh = trimesh.load(stego_path)\n","\n","            # Check if loaded data is a Scene and extract the first mesh if it is\n","            if isinstance(original_mesh, trimesh.Scene):\n","                original_mesh = next(iter(original_mesh.geometry.values())) # Get the first mesh from the scene\n","            if isinstance(stego_mesh, trimesh.Scene):\n","                stego_mesh = next(iter(stego_mesh.geometry.values())) # Get the first mesh from the scene\n","\n","            print(f\"Original vertices: {len(original_mesh.vertices)}\")\n","            print(f\"Stego vertices: {len(stego_mesh.vertices)}\")\n","\n","            # Preprocess meshes\n","            original_mesh, stego_mesh = self.preprocess_models(original_mesh, stego_mesh)\n","\n","            if align:\n","                # Align vertices\n","                self.original_vertices, self.stego_vertices, distances = self.align_vertices(\n","                    original_mesh.vertices,\n","                    stego_mesh.vertices\n","                )\n","\n","                # Print alignment statistics\n","                print(f\"\\nAlignment Statistics:\")\n","                print(f\"Mean distance: {np.mean(distances):.6f}\")\n","                print(f\"Max distance: {np.max(distances):.6f}\")\n","                print(f\"Aligned vertices: {len(self.original_vertices)}\")\n","            else:\n","                if len(original_mesh.vertices) != len(stego_mesh.vertices):\n","                    raise ValueError(\"Models have different number of vertices and alignment is disabled\")\n","                self.original_vertices = original_mesh.vertices\n","                self.stego_vertices = stego_mesh.vertices\n","\n","            self.original_mesh = original_mesh\n","            self.stego_mesh = stego_mesh\n","\n","            return True\n","\n","        except Exception as e:\n","            print(f\"Error loading models: {str(e)}\")\n","            return False\n","\n","    def calculate_vertex_error_map(self):\n","        \"\"\"Calculate and visualize vertex-wise errors\"\"\"\n","        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n","        return errors\n","\n","\n","\n","    def calculate_psnr(self):\n","        \"\"\"Calculate Peak Signal-to-Noise Ratio\"\"\"\n","        mse = np.mean((self.original_vertices - self.stego_vertices) ** 2)\n","        if mse == 0:\n","            return float('inf')\n","\n","        max_val = np.max(self.original_vertices) - np.min(self.original_vertices)\n","        psnr = 20 * math.log10(max_val / math.sqrt(mse))\n","        self.metrics['PSNR'] = psnr\n","        return psnr\n","\n","    def calculate_ssim(self):\n","        \"\"\"Calculate Structural Similarity Index\"\"\"\n","        orig_reshaped = self.original_vertices.reshape(-1, 3)\n","        stego_reshaped = self.stego_vertices.reshape(-1, 3)\n","\n","        ssim_scores = []\n","        for i in range(3):\n","            score = structural_similarity(\n","                orig_reshaped[:, i],\n","                stego_reshaped[:, i],\n","                data_range=np.max(orig_reshaped[:, i]) - np.min(orig_reshaped[:, i])\n","            )\n","            ssim_scores.append(score)\n","\n","        ssim = np.mean(ssim_scores)\n","        self.metrics['SSIM'] = ssim\n","        return ssim\n","\n","    def calculate_mse(self):\n","        \"\"\"Calculate Mean Squared Error\"\"\"\n","        mse = mean_squared_error(self.original_vertices, self.stego_vertices)\n","        self.metrics['MSE'] = mse\n","        return mse\n","\n","    def calculate_rmse(self):\n","        \"\"\"Calculate Root Mean Squared Error\"\"\"\n","        rmse = np.sqrt(self.calculate_mse())\n","        self.metrics['RMSE'] = rmse\n","        return rmse\n","\n","    def calculate_ber(self, threshold=1e-6):\n","        \"\"\"Calculate Bit Error Rate\"\"\"\n","        differences = np.abs(self.original_vertices - self.stego_vertices)\n","        binary_orig = (self.original_vertices > threshold).astype(int)\n","        binary_stego = (self.stego_vertices > threshold).astype(int)\n","\n","        total_bits = np.prod(binary_orig.shape)\n","        error_bits = np.sum(binary_orig != binary_stego)\n","\n","        ber = error_bits / total_bits\n","        self.metrics['BER'] = ber\n","        return ber\n","\n","    def calculate_hausdorff_distance(self):\n","        \"\"\"Calculate Hausdorff distance between original and stego models\"\"\"\n","        def directed_hausdorff(source, target):\n","            tree = KDTree(target)\n","            distances, _ = tree.query(source)\n","            return np.max(distances)\n","\n","        forward = directed_hausdorff(self.original_vertices, self.stego_vertices)\n","        backward = directed_hausdorff(self.stego_vertices, self.original_vertices)\n","\n","        hausdorff = max(forward, backward)\n","        self.metrics['Hausdorff'] = hausdorff\n","        return hausdorff\n","\n","    def calculate_histogram_similarity(self, bins=50):\n","        \"\"\"Calculate histogram similarity using Wasserstein distance\"\"\"\n","        distances = []\n","\n","        for i in range(3):\n","            hist_orig, _ = np.histogram(self.original_vertices[:, i], bins=bins, density=True)\n","            hist_stego, _ = np.histogram(self.stego_vertices[:, i], bins=bins, density=True)\n","\n","            distance = wasserstein_distance(hist_orig, hist_stego)\n","            distances.append(distance)\n","\n","        hist_similarity = 1 / (1 + np.mean(distances))\n","        self.metrics['Histogram_Similarity'] = hist_similarity\n","        return hist_similarity\n","\n","    def plot_histograms(self, save_path=None):\n","        \"\"\"Plot histograms of original and stego models\"\"\"\n","        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","        coords = ['X', 'Y', 'Z']\n","\n","        for i, (ax, coord) in enumerate(zip(axes, coords)):\n","            ax.hist(self.original_vertices[:, i], bins=50, alpha=0.5, label='Original', density=True)\n","            ax.hist(self.stego_vertices[:, i], bins=50, alpha=0.5, label='Stego', density=True)\n","            ax.set_title(f'{coord} Coordinate Distribution')\n","            ax.set_xlabel(f'{coord} Value')\n","            ax.set_ylabel('Density')\n","            ax.legend()\n","\n","        plt.tight_layout()\n","        if save_path:\n","            plt.savefig(save_path)\n","            plt.close()\n","        else:\n","            plt.show()\n","\n","    def plot_error_distribution(self, save_path=None):\n","        \"\"\"Plot the distribution of geometric errors\"\"\"\n","        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n","\n","        plt.figure(figsize=(10, 6))\n","        plt.hist(errors, bins=50, density=True)\n","        plt.title('Geometric Error Distribution')\n","        plt.xlabel('Error Magnitude')\n","        plt.ylabel('Density')\n","\n","        if save_path:\n","            plt.savefig(save_path)\n","            plt.close()\n","        else:\n","            plt.show()\n","\n","    def evaluate_all(self, plot=True, save_plots=False):\n","        \"\"\"Calculate all metrics and optionally generate plots\"\"\"\n","        metrics = {\n","            'PSNR': self.calculate_psnr(),\n","            'SSIM': self.calculate_ssim(),\n","            'MSE': self.calculate_mse(),\n","            'RMSE': self.calculate_rmse(),\n","            'BER': self.calculate_ber(),\n","            'Hausdorff': self.calculate_hausdorff_distance(),\n","            'Histogram_Similarity': self.calculate_histogram_similarity()\n","        }\n","\n","        if plot:\n","            self.plot_histograms(save_path='/content/drive/MyDrive/OutputPaper2/histograms_RiggedHand_.png' if save_plots else None)\n","            self.plot_error_distribution(save_path='/content/drive/MyDrive/OutputPaper2/error_distribution_RiggedHand.png' if save_plots else None)\n","            #self.visualize_error_map(save_path='error_map.png' if save_plots else None)\n","\n","        return metrics\n","    def generate_report(self, output_path='/content/drive/MyDrive/OutputPaper2/evaluation_report_RiggedHand.txt'):\n","        \"\"\"Generate a detailed evaluation report\"\"\"\n","        with open(output_path, 'w') as f:\n","            f.write(\"3D Steganography Evaluation Report\\n\")\n","            f.write(\"=================================\\n\\n\")\n","\n","            # Model information\n","            f.write(\"Model Information:\\n\")\n","            f.write(f\"Number of vertices: {len(self.original_vertices)}\\n\")\n","            f.write(f\"Number of faces: {len(self.original_mesh.faces)}\\n\\n\")\n","\n","            # Metrics\n","            f.write(\"Quality Metrics:\\n\")\n","            for metric, value in self.metrics.items():\n","                f.write(f\"{metric}: {value:.6f}\\n\")\n","\n","            f.write(\"\\nInterpretation:\\n\")\n","            f.write(\"- PSNR > 30 dB typically indicates good quality\\n\")\n","            f.write(\"- SSIM closer to 1 indicates better structural preservation\\n\")\n","            f.write(\"- Lower MSE and RMSE values indicate better similarity\\n\")\n","            f.write(\"- Lower BER indicates better steganographic accuracy\\n\")\n","            f.write(\"- Histogram similarity closer to 1 indicates better statistical imperceptibility\\n\")\n","\n","def main():\n","    # Initialize evaluator\n","    evaluator = Stego3DEvaluator()\n","\n","    # Load and align models\n","    if not evaluator.load_models('/content/drive/MyDrive/OutputPaper2/modified_RiggedHand.obj', '/content/drive/MyDrive/OutputPaper2/RiggedHand.obj', align=True):\n","        return\n","\n","    # Perform evaluation\n","    metrics = evaluator.evaluate_all(plot=True, save_plots=True)\n","\n","    # Print results\n","    print(\"\\nEvaluation Results:\")\n","    for metric, value in metrics.items():\n","        print(f\"{metric}: {value:.6f}\")\n","    evaluator.generate_report()\n","    print(\"\\nDetailed report saved to '/content/drive/MyDrive/OutputPaper2/evaluation_report_RiggedHand.txt'\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736790686321,"user_tz":-300,"elapsed":3884,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"outputId":"97b6ee0a-37c8-4b49-9402-f4d8607ebe47","id":"w8vZDDo0I3TB"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Original vertices: 1071\n","Stego vertices: 1071\n","\n","Alignment Statistics:\n","Mean distance: 0.000219\n","Max distance: 0.001156\n","Aligned vertices: 1071\n","\n","Evaluation Results:\n","PSNR: 77.491462\n","SSIM: 0.997490\n","MSE: 0.000000\n","RMSE: 0.000264\n","BER: 0.000622\n","Hausdorff: 0.001156\n","Histogram_Similarity: 0.702856\n","\n","Detailed report saved to '/content/drive/MyDrive/OutputPaper2/evaluation_report_RiggedHand.txt'\n"]}]},{"cell_type":"markdown","source":["Embedding for 16834_hand_v1_NEW"],"metadata":{"id":"a1lUuc5021_n"}},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"status":"ok","timestamp":1736791419903,"user_tz":-300,"elapsed":423,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"id":"bEwNRE1wzHmH"},"outputs":[],"source":["#!pip install pycryptodome\n","#!pip install trimesh\n","import numpy as np\n","from Crypto.Cipher import AES\n","from Crypto.Util.Padding import pad, unpad\n","import hashlib\n","import secrets\n","import struct\n","import trimesh\n","import scipy.spatial as spatial\n","\n","class SecureFaceSteganography:\n","    def __init__(self):\n","        # ... (other code)\n","        self.LANDMARK_REGIONS = {\n","            'forehead': [(0.2, 0.8, 0.5), (0.8, 0.8, 0.5)],  # Wider bounding box\n","            'cheeks': [(0.1, 0.5, 0.5), (0.9, 0.5, 0.5)],  # Wider bounding box\n","            'jaw': [(0.2, 0.2, 0.5), (0.8, 0.2, 0.5)],  # Wider bounding box\n","            'nose': [(0.4, 0.6, 0.5), (0.6, 0.6, 0.5)],  # Added nose region\n","            'chin': [(0.5, 0.1, 0.5)]  #chin region\n","        }\n","        # Define SALT_SIZE and BLOCK_SIZE in the __init__ method\n","        self.SALT_SIZE = 16  # 128 bits for salt\n","        self.BLOCK_SIZE = 16 # 128 bits for block size\n","        self.distributed_landmarks = None  # Initialize distributed_landmarks\n","\n","    def load_face_model(self, file_path):\n","        \"\"\"Load 3D face model and prepare it for steganography\"\"\"\n","        try:\n","            loaded_data = trimesh.load(file_path)\n","            # Check if loaded_data is a Scene and extract the first mesh if it is\n","            if isinstance(loaded_data, trimesh.Scene):\n","                mesh = next(iter(loaded_data.geometry.values())) # Get the first mesh from the scene\n","            else:\n","                mesh = loaded_data\n","\n","            return {\n","                'vertices': np.array(mesh.vertices),\n","                'faces': np.array(mesh.faces),\n","                'normals': np.array(mesh.vertex_normals)\n","            }\n","        except Exception as e:\n","            raise ValueError(f\"Error loading face model: {str(e)}\")\n","\n","    def identify_landmark_vertices(self, vertices, landmark_regions=None):\n","        if landmark_regions is None:\n","            landmark_regions = self.LANDMARK_REGIONS\n","\n","        # Use stored landmarks if available, otherwise generate\n","        if self.distributed_landmarks is None:\n","            num_landmarks = min(1000, len(vertices))\n","            self.distributed_landmarks = np.random.choice(len(vertices), num_landmarks, replace=False)\n","\n","        return sorted(self.distributed_landmarks)  # Return stored landmarks\n","\n","    def compute_vertex_importance(self, vertices, faces, normals):\n","        \"\"\"Compute vertex importance based on geometric features\"\"\"\n","        importance = np.zeros(len(vertices))\n","\n","        # Calculate curvature (simplified)\n","        for i, vertex in enumerate(vertices):\n","            # Find connected vertices\n","            connected = faces[np.any(faces == i, axis=1)]\n","            connected = np.unique(connected.flatten())\n","            connected = connected[connected != i]\n","\n","            # Calculate local curvature\n","            if len(connected) > 0:\n","                connected_vertices = vertices[connected]\n","                mean_position = np.mean(connected_vertices, axis=0)\n","                displacement = np.linalg.norm(vertex - mean_position)\n","                importance[i] = displacement\n","\n","        return importance\n","\n","    def generate_passphrase(self, length=32):\n","        \"\"\"Generate a cryptographically secure random passphrase\"\"\"\n","        charset = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&*\"\n","        return ''.join(secrets.choice(charset) for _ in range(length))\n","\n","    def derive_key(self, passphrase, salt):\n","        \"\"\"Derive encryption key using SHA-256 with salt\"\"\"\n","        key_material = hashlib.sha256()\n","        key_material.update(passphrase.encode('utf-8'))\n","        key_material.update(salt)\n","        return key_material.digest()\n","\n","    def encrypt_message(self, message, passphrase):\n","        \"\"\"Encrypt a message using AES-128-CBC with secure key derivation\"\"\"\n","        salt = secrets.token_bytes(self.SALT_SIZE)\n","        key = self.derive_key(passphrase, salt)\n","        iv = secrets.token_bytes(self.BLOCK_SIZE)\n","\n","        cipher = AES.new(key, AES.MODE_CBC, iv)\n","        padded_data = pad(message.encode('utf-8'), self.BLOCK_SIZE)\n","        ciphertext = cipher.encrypt(padded_data)\n","\n","        return salt + iv + ciphertext\n","\n","    def decrypt_message(self, encrypted_data, passphrase):\n","        \"\"\"Decrypt a message using AES-128-CBC\"\"\"\n","        salt = encrypted_data[:self.SALT_SIZE]\n","        iv = encrypted_data[self.SALT_SIZE:self.SALT_SIZE + self.BLOCK_SIZE]\n","        ciphertext = encrypted_data[self.SALT_SIZE + self.BLOCK_SIZE:]\n","\n","        key = self.derive_key(passphrase, salt)\n","        cipher = AES.new(key, AES.MODE_CBC, iv)\n","\n","        # Attempt to decrypt. Handle potential padding errors\n","        try:\n","            padded_message = cipher.decrypt(ciphertext)\n","            return unpad(padded_message, self.BLOCK_SIZE).decode('utf-8')\n","        except ValueError:\n","            print(\"Warning: Decryption failed. Possible data corruption or incorrect passphrase.\")\n","            return None  # or raise a more specific exception\n","\n","\n","    def embed_in_face_model(self, face_model, encrypted_data):\n","        \"\"\"Embed encrypted data in 3D face model using geometric features\"\"\"\n","        vertices = face_model['vertices'].copy()\n","        faces = face_model['faces']\n","        normals = face_model['normals']\n","\n","        # Get landmarks and importance metrics\n","        landmark_vertices = self.identify_landmark_vertices(vertices)\n","        importance = self.compute_vertex_importance(vertices, faces, normals)\n","\n","        # Convert encrypted data to bit array\n","        bit_array = ''.join(format(byte, '08b') for byte in encrypted_data)\n","\n","        # Check if the message is too large\n","        if len(bit_array) > len(landmark_vertices):\n","            raise ValueError(f\"Message too large for this face model. Message bits: {len(bit_array)}, Available vertices: {len(landmark_vertices)}\")\n","\n","        # Embed data in vertices near landmarks using rounding and a larger scale factor\n","        for i, bit in enumerate(bit_array):\n","            vertex_idx = landmark_vertices[i]\n","            scale_factor = 0.001 * (1 - importance[vertex_idx])  # Significantly increased scale_factor\n","\n","            # Apply rounding to the modification\n","            modification = round(float(bit) * scale_factor, 6)  # Round to 6 decimal places\n","\n","            vertices[vertex_idx] += modification * normals[vertex_idx]\n","\n","        face_model['vertices'] = vertices\n","        return face_model\n","\n","    def extract_from_face_model(self, face_model, original_model, message_length):\n","        \"\"\"Extract encrypted data from modified 3D face model\"\"\"\n","        modified_vertices = face_model['vertices']\n","        original_vertices = original_model['vertices']\n","        landmark_vertices = self.identify_landmark_vertices(original_vertices)\n","\n","        bits = []\n","        for i in range(message_length * 8):  # Iterate over the expected number of bits\n","            if i >= len(landmark_vertices):\n","                print(f\"Warning: Not enough landmark vertices to extract the full message. Extracted {i} bits, expected {message_length * 8} bits.\")\n","                break  # Stop if we run out of landmark vertices\n","            vertex_idx = landmark_vertices[i]\n","\n","            # Compare modified vertex with original\n","            diff = modified_vertices[vertex_idx] - original_vertices[vertex_idx]\n","            # Extract bit based on vertex displacement using a tolerance\n","\n","            extracted_bit = np.dot(diff, original_model['normals'][vertex_idx]) #Using original normals\n","\n","            #Using tolerance instead of direct comparison with 0\n","            bit = '1' if extracted_bit > 1e-6 else '0'\n","            bits.append(bit)\n","\n","        # Convert bits back to bytes\n","        extracted_data = bytes(\n","            int(''.join(bits[i:i + 8]), 2) for i in range(0, len(bits), 8)\n","        )\n","\n","        return extracted_data\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7048e005-8d6d-4ac5-f574-ee315fb8c017","executionInfo":{"status":"ok","timestamp":1736791649387,"user_tz":-300,"elapsed":226974,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"id":"sgF2ByuAzMcA"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generated passphrase: 7D^Fm11diBKtbn91h!0u$zRFmbUzv^%&\n","Original message: short\n","Decrypted message: short\n"]}],"source":["def main():\n","    # Initialize steganography system\n","    stego = SecureFaceSteganography()\n","\n","    # Load 3D face model (example path)\n","    face_model = stego.load_face_model('/content/drive/MyDrive/OutputPaper2/16834_hand_v1_NEW.obj')\n","    original_model = {key: value.copy() for key, value in face_model.items()}\n","\n","    # Generate secure passphrase\n","    passphrase = stego.generate_passphrase()\n","    print(f\"Generated passphrase: {passphrase}\")\n","\n","    # Message to hide - Reduced length to fit within the model's capacity\n","    secret_message = \"short\"\n","\n","    # Encrypt the message\n","    encrypted_data = stego.encrypt_message(secret_message, passphrase)\n","\n","    # Embed encrypted data in face model\n","    modified_model = stego.embed_in_face_model(face_model, encrypted_data)\n","\n","    # Extract and decrypt\n","    extracted_data = stego.extract_from_face_model(\n","        modified_model, original_model, len(encrypted_data)\n","    )\n","    decrypted_message = stego.decrypt_message(extracted_data, passphrase)\n","\n","    print(f\"Original message: {secret_message}\")\n","    print(f\"Decrypted message: {decrypted_message}\")\n","\n","    # Save modified model\n","    mesh = trimesh.Trimesh(\n","        vertices=modified_model['vertices'],\n","        faces=modified_model['faces']\n","    )\n","    mesh.export('/content/drive/MyDrive/OutputPaper2/modified_16834_hand_v1_NEW.obj')\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","source":["Evaluation for 16834_hand_v1_NEW"],"metadata":{"id":"3pdap-H33ACO"}},{"source":["#!pip install pyglet\n","#!pip install pyglet<2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error\n","import trimesh\n","from scipy.stats import wasserstein_distance\n","from skimage.metrics import structural_similarity\n","import math\n","from scipy.spatial import KDTree\n","import os\n","\n","class Stego3DEvaluator:\n","    def __init__(self):\n","        \"\"\"Initialize the 3D steganography evaluator\"\"\"\n","        self.metrics = {}\n","\n","    def preprocess_models(self, original_mesh, stego_mesh):\n","        \"\"\"Preprocess and align models to ensure compatibility\"\"\"\n","        # Center both meshes\n","        original_mesh.vertices -= original_mesh.vertices.mean(axis=0)\n","        stego_mesh.vertices -= stego_mesh.vertices.mean(axis=0)\n","\n","        # Scale to unit cube\n","        original_scale = np.max(np.abs(original_mesh.vertices))\n","        stego_scale = np.max(np.abs(stego_mesh.vertices))\n","\n","        original_mesh.vertices /= original_scale\n","        stego_mesh.vertices /= stego_scale\n","\n","        return original_mesh, stego_mesh\n","\n","    def align_vertices(self, original_vertices, stego_vertices):\n","        \"\"\"Align vertices between models using nearest neighbor matching\"\"\"\n","        # Build KD-tree for faster nearest neighbor search\n","        tree = KDTree(original_vertices)\n","\n","        # Find nearest neighbors for each stego vertex\n","        distances, indices = tree.query(stego_vertices)\n","\n","        # Create aligned vertex arrays\n","        aligned_original = original_vertices[indices]\n","        aligned_stego = stego_vertices\n","\n","        return aligned_original, aligned_stego, distances\n","\n","    def load_models(self, original_path, stego_path, align=True):\n","        \"\"\"Load and preprocess original and stego 3D models\"\"\"\n","        try:\n","            # Load meshes\n","            original_mesh = trimesh.load(original_path)\n","            stego_mesh = trimesh.load(stego_path)\n","\n","            # Check if loaded data is a Scene and extract the first mesh if it is\n","            if isinstance(original_mesh, trimesh.Scene):\n","                original_mesh = next(iter(original_mesh.geometry.values())) # Get the first mesh from the scene\n","            if isinstance(stego_mesh, trimesh.Scene):\n","                stego_mesh = next(iter(stego_mesh.geometry.values())) # Get the first mesh from the scene\n","\n","            print(f\"Original vertices: {len(original_mesh.vertices)}\")\n","            print(f\"Stego vertices: {len(stego_mesh.vertices)}\")\n","\n","            # Preprocess meshes\n","            original_mesh, stego_mesh = self.preprocess_models(original_mesh, stego_mesh)\n","\n","            if align:\n","                # Align vertices\n","                self.original_vertices, self.stego_vertices, distances = self.align_vertices(\n","                    original_mesh.vertices,\n","                    stego_mesh.vertices\n","                )\n","\n","                # Print alignment statistics\n","                print(f\"\\nAlignment Statistics:\")\n","                print(f\"Mean distance: {np.mean(distances):.6f}\")\n","                print(f\"Max distance: {np.max(distances):.6f}\")\n","                print(f\"Aligned vertices: {len(self.original_vertices)}\")\n","            else:\n","                if len(original_mesh.vertices) != len(stego_mesh.vertices):\n","                    raise ValueError(\"Models have different number of vertices and alignment is disabled\")\n","                self.original_vertices = original_mesh.vertices\n","                self.stego_vertices = stego_mesh.vertices\n","\n","            self.original_mesh = original_mesh\n","            self.stego_mesh = stego_mesh\n","\n","            return True\n","\n","        except Exception as e:\n","            print(f\"Error loading models: {str(e)}\")\n","            return False\n","\n","    def calculate_vertex_error_map(self):\n","        \"\"\"Calculate and visualize vertex-wise errors\"\"\"\n","        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n","        return errors\n","\n","\n","\n","    def calculate_psnr(self):\n","        \"\"\"Calculate Peak Signal-to-Noise Ratio\"\"\"\n","        mse = np.mean((self.original_vertices - self.stego_vertices) ** 2)\n","        if mse == 0:\n","            return float('inf')\n","\n","        max_val = np.max(self.original_vertices) - np.min(self.original_vertices)\n","        psnr = 20 * math.log10(max_val / math.sqrt(mse))\n","        self.metrics['PSNR'] = psnr\n","        return psnr\n","\n","    def calculate_ssim(self):\n","        \"\"\"Calculate Structural Similarity Index\"\"\"\n","        orig_reshaped = self.original_vertices.reshape(-1, 3)\n","        stego_reshaped = self.stego_vertices.reshape(-1, 3)\n","\n","        ssim_scores = []\n","        for i in range(3):\n","            score = structural_similarity(\n","                orig_reshaped[:, i],\n","                stego_reshaped[:, i],\n","                data_range=np.max(orig_reshaped[:, i]) - np.min(orig_reshaped[:, i])\n","            )\n","            ssim_scores.append(score)\n","\n","        ssim = np.mean(ssim_scores)\n","        self.metrics['SSIM'] = ssim\n","        return ssim\n","\n","    def calculate_mse(self):\n","        \"\"\"Calculate Mean Squared Error\"\"\"\n","        mse = mean_squared_error(self.original_vertices, self.stego_vertices)\n","        self.metrics['MSE'] = mse\n","        return mse\n","\n","    def calculate_rmse(self):\n","        \"\"\"Calculate Root Mean Squared Error\"\"\"\n","        rmse = np.sqrt(self.calculate_mse())\n","        self.metrics['RMSE'] = rmse\n","        return rmse\n","\n","    def calculate_ber(self, threshold=1e-6):\n","        \"\"\"Calculate Bit Error Rate\"\"\"\n","        differences = np.abs(self.original_vertices - self.stego_vertices)\n","        binary_orig = (self.original_vertices > threshold).astype(int)\n","        binary_stego = (self.stego_vertices > threshold).astype(int)\n","\n","        total_bits = np.prod(binary_orig.shape)\n","        error_bits = np.sum(binary_orig != binary_stego)\n","\n","        ber = error_bits / total_bits\n","        self.metrics['BER'] = ber\n","        return ber\n","\n","    def calculate_hausdorff_distance(self):\n","        \"\"\"Calculate Hausdorff distance between original and stego models\"\"\"\n","        def directed_hausdorff(source, target):\n","            tree = KDTree(target)\n","            distances, _ = tree.query(source)\n","            return np.max(distances)\n","\n","        forward = directed_hausdorff(self.original_vertices, self.stego_vertices)\n","        backward = directed_hausdorff(self.stego_vertices, self.original_vertices)\n","\n","        hausdorff = max(forward, backward)\n","        self.metrics['Hausdorff'] = hausdorff\n","        return hausdorff\n","\n","    def calculate_histogram_similarity(self, bins=50):\n","        \"\"\"Calculate histogram similarity using Wasserstein distance\"\"\"\n","        distances = []\n","\n","        for i in range(3):\n","            hist_orig, _ = np.histogram(self.original_vertices[:, i], bins=bins, density=True)\n","            hist_stego, _ = np.histogram(self.stego_vertices[:, i], bins=bins, density=True)\n","\n","            distance = wasserstein_distance(hist_orig, hist_stego)\n","            distances.append(distance)\n","\n","        hist_similarity = 1 / (1 + np.mean(distances))\n","        self.metrics['Histogram_Similarity'] = hist_similarity\n","        return hist_similarity\n","\n","    def plot_histograms(self, save_path=None):\n","        \"\"\"Plot histograms of original and stego models\"\"\"\n","        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","        coords = ['X', 'Y', 'Z']\n","\n","        for i, (ax, coord) in enumerate(zip(axes, coords)):\n","            ax.hist(self.original_vertices[:, i], bins=50, alpha=0.5, label='Original', density=True)\n","            ax.hist(self.stego_vertices[:, i], bins=50, alpha=0.5, label='Stego', density=True)\n","            ax.set_title(f'{coord} Coordinate Distribution')\n","            ax.set_xlabel(f'{coord} Value')\n","            ax.set_ylabel('Density')\n","            ax.legend()\n","\n","        plt.tight_layout()\n","        if save_path:\n","            plt.savefig(save_path)\n","            plt.close()\n","        else:\n","            plt.show()\n","\n","    def plot_error_distribution(self, save_path=None):\n","        \"\"\"Plot the distribution of geometric errors\"\"\"\n","        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n","\n","        plt.figure(figsize=(10, 6))\n","        plt.hist(errors, bins=50, density=True)\n","        plt.title('Geometric Error Distribution')\n","        plt.xlabel('Error Magnitude')\n","        plt.ylabel('Density')\n","\n","        if save_path:\n","            plt.savefig(save_path)\n","            plt.close()\n","        else:\n","            plt.show()\n","\n","    def evaluate_all(self, plot=True, save_plots=False):\n","        \"\"\"Calculate all metrics and optionally generate plots\"\"\"\n","        metrics = {\n","            'PSNR': self.calculate_psnr(),\n","            'SSIM': self.calculate_ssim(),\n","            'MSE': self.calculate_mse(),\n","            'RMSE': self.calculate_rmse(),\n","            'BER': self.calculate_ber(),\n","            'Hausdorff': self.calculate_hausdorff_distance(),\n","            'Histogram_Similarity': self.calculate_histogram_similarity()\n","        }\n","\n","        if plot:\n","            self.plot_histograms(save_path='/content/drive/MyDrive/OutputPaper2/histograms_16834_hand_v1_NEW_.png' if save_plots else None)\n","            self.plot_error_distribution(save_path='/content/drive/MyDrive/OutputPaper2/error_distribution_16834_hand_v1_NEW.png' if save_plots else None)\n","            #self.visualize_error_map(save_path='error_map.png' if save_plots else None)\n","\n","        return metrics\n","    def generate_report(self, output_path='/content/drive/MyDrive/OutputPaper2/evaluation_report_16834_hand_v1_NEW.txt'):\n","        \"\"\"Generate a detailed evaluation report\"\"\"\n","        with open(output_path, 'w') as f:\n","            f.write(\"3D Steganography Evaluation Report\\n\")\n","            f.write(\"=================================\\n\\n\")\n","\n","            # Model information\n","            f.write(\"Model Information:\\n\")\n","            f.write(f\"Number of vertices: {len(self.original_vertices)}\\n\")\n","            f.write(f\"Number of faces: {len(self.original_mesh.faces)}\\n\\n\")\n","\n","            # Metrics\n","            f.write(\"Quality Metrics:\\n\")\n","            for metric, value in self.metrics.items():\n","                f.write(f\"{metric}: {value:.6f}\\n\")\n","\n","            f.write(\"\\nInterpretation:\\n\")\n","            f.write(\"- PSNR > 30 dB typically indicates good quality\\n\")\n","            f.write(\"- SSIM closer to 1 indicates better structural preservation\\n\")\n","            f.write(\"- Lower MSE and RMSE values indicate better similarity\\n\")\n","            f.write(\"- Lower BER indicates better steganographic accuracy\\n\")\n","            f.write(\"- Histogram similarity closer to 1 indicates better statistical imperceptibility\\n\")\n","\n","def main():\n","    # Initialize evaluator\n","    evaluator = Stego3DEvaluator()\n","\n","    # Load and align models\n","    if not evaluator.load_models('/content/drive/MyDrive/OutputPaper2/modified_16834_hand_v1_NEW.obj', '/content/drive/MyDrive/OutputPaper2/16834_hand_v1_NEW.obj', align=True):\n","        return\n","\n","    # Perform evaluation\n","    metrics = evaluator.evaluate_all(plot=True, save_plots=True)\n","\n","    # Print results\n","    print(\"\\nEvaluation Results:\")\n","    for metric, value in metrics.items():\n","        print(f\"{metric}: {value:.6f}\")\n","    evaluator.generate_report()\n","    print(\"\\nDetailed report saved to '/content/drive/MyDrive/OutputPaper2/evaluation_report_16834_hand_v1_NEW.txt'\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736791708548,"user_tz":-300,"elapsed":2902,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"outputId":"f80ad52d-34db-4733-fcbb-9d18739d77f2","id":"peUfbkqhzQ4n"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Original vertices: 66848\n","Stego vertices: 66848\n","\n","Alignment Statistics:\n","Mean distance: 0.000000\n","Max distance: 0.000081\n","Aligned vertices: 66848\n","\n","Evaluation Results:\n","PSNR: 115.993959\n","SSIM: 1.000000\n","MSE: 0.000000\n","RMSE: 0.000003\n","BER: 0.000000\n","Hausdorff: 0.000081\n","Histogram_Similarity: 0.999960\n","\n","Detailed report saved to '/content/drive/MyDrive/OutputPaper2/evaluation_report_16834_hand_v1_NEW.txt'\n"]}]},{"cell_type":"markdown","source":["Embedding for 15807_Zombie_Hand_v1_NEW"],"metadata":{"id":"QzsPlsUG4RGW"}},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"status":"ok","timestamp":1736792303941,"user_tz":-300,"elapsed":452,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"id":"PJagCmri4OXy"},"outputs":[],"source":["#!pip install pycryptodome\n","#!pip install trimesh\n","import numpy as np\n","from Crypto.Cipher import AES\n","from Crypto.Util.Padding import pad, unpad\n","import hashlib\n","import secrets\n","import struct\n","import trimesh\n","import scipy.spatial as spatial\n","\n","class SecureFaceSteganography:\n","    def __init__(self):\n","        # ... (other code)\n","        self.LANDMARK_REGIONS = {\n","            'forehead': [(0.2, 0.8, 0.5), (0.8, 0.8, 0.5)],  # Wider bounding box\n","            'cheeks': [(0.1, 0.5, 0.5), (0.9, 0.5, 0.5)],  # Wider bounding box\n","            'jaw': [(0.2, 0.2, 0.5), (0.8, 0.2, 0.5)],  # Wider bounding box\n","            'nose': [(0.4, 0.6, 0.5), (0.6, 0.6, 0.5)],  # Added nose region\n","            'chin': [(0.5, 0.1, 0.5)]  #chin region\n","        }\n","        # Define SALT_SIZE and BLOCK_SIZE in the __init__ method\n","        self.SALT_SIZE = 16  # 128 bits for salt\n","        self.BLOCK_SIZE = 16 # 128 bits for block size\n","        self.distributed_landmarks = None  # Initialize distributed_landmarks\n","\n","    def load_face_model(self, file_path):\n","        \"\"\"Load 3D face model and prepare it for steganography\"\"\"\n","        try:\n","            loaded_data = trimesh.load(file_path)\n","            # Check if loaded_data is a Scene and extract the first mesh if it is\n","            if isinstance(loaded_data, trimesh.Scene):\n","                mesh = next(iter(loaded_data.geometry.values())) # Get the first mesh from the scene\n","            else:\n","                mesh = loaded_data\n","\n","            return {\n","                'vertices': np.array(mesh.vertices),\n","                'faces': np.array(mesh.faces),\n","                'normals': np.array(mesh.vertex_normals)\n","            }\n","        except Exception as e:\n","            raise ValueError(f\"Error loading face model: {str(e)}\")\n","\n","    def identify_landmark_vertices(self, vertices, landmark_regions=None):\n","        if landmark_regions is None:\n","            landmark_regions = self.LANDMARK_REGIONS\n","\n","        # Use stored landmarks if available, otherwise generate\n","        if self.distributed_landmarks is None:\n","            num_landmarks = min(1000, len(vertices))\n","            self.distributed_landmarks = np.random.choice(len(vertices), num_landmarks, replace=False)\n","\n","        return sorted(self.distributed_landmarks)  # Return stored landmarks\n","\n","    def compute_vertex_importance(self, vertices, faces, normals):\n","        \"\"\"Compute vertex importance based on geometric features\"\"\"\n","        importance = np.zeros(len(vertices))\n","\n","        # Calculate curvature (simplified)\n","        for i, vertex in enumerate(vertices):\n","            # Find connected vertices\n","            connected = faces[np.any(faces == i, axis=1)]\n","            connected = np.unique(connected.flatten())\n","            connected = connected[connected != i]\n","\n","            # Calculate local curvature\n","            if len(connected) > 0:\n","                connected_vertices = vertices[connected]\n","                mean_position = np.mean(connected_vertices, axis=0)\n","                displacement = np.linalg.norm(vertex - mean_position)\n","                importance[i] = displacement\n","\n","        return importance\n","\n","    def generate_passphrase(self, length=32):\n","        \"\"\"Generate a cryptographically secure random passphrase\"\"\"\n","        charset = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&*\"\n","        return ''.join(secrets.choice(charset) for _ in range(length))\n","\n","    def derive_key(self, passphrase, salt):\n","        \"\"\"Derive encryption key using SHA-256 with salt\"\"\"\n","        key_material = hashlib.sha256()\n","        key_material.update(passphrase.encode('utf-8'))\n","        key_material.update(salt)\n","        return key_material.digest()\n","\n","    def encrypt_message(self, message, passphrase):\n","        \"\"\"Encrypt a message using AES-128-CBC with secure key derivation\"\"\"\n","        salt = secrets.token_bytes(self.SALT_SIZE)\n","        key = self.derive_key(passphrase, salt)\n","        iv = secrets.token_bytes(self.BLOCK_SIZE)\n","\n","        cipher = AES.new(key, AES.MODE_CBC, iv)\n","        padded_data = pad(message.encode('utf-8'), self.BLOCK_SIZE)\n","        ciphertext = cipher.encrypt(padded_data)\n","\n","        return salt + iv + ciphertext\n","\n","    def decrypt_message(self, encrypted_data, passphrase):\n","        \"\"\"Decrypt a message using AES-128-CBC\"\"\"\n","        salt = encrypted_data[:self.SALT_SIZE]\n","        iv = encrypted_data[self.SALT_SIZE:self.SALT_SIZE + self.BLOCK_SIZE]\n","        ciphertext = encrypted_data[self.SALT_SIZE + self.BLOCK_SIZE:]\n","\n","        key = self.derive_key(passphrase, salt)\n","        cipher = AES.new(key, AES.MODE_CBC, iv)\n","\n","        # Attempt to decrypt. Handle potential padding errors\n","        try:\n","            padded_message = cipher.decrypt(ciphertext)\n","            return unpad(padded_message, self.BLOCK_SIZE).decode('utf-8')\n","        except ValueError:\n","            print(\"Warning: Decryption failed. Possible data corruption or incorrect passphrase.\")\n","            return None  # or raise a more specific exception\n","\n","\n","    def embed_in_face_model(self, face_model, encrypted_data):\n","        \"\"\"Embed encrypted data in 3D face model using geometric features\"\"\"\n","        vertices = face_model['vertices'].copy()\n","        faces = face_model['faces']\n","        normals = face_model['normals']\n","\n","        # Get landmarks and importance metrics\n","        landmark_vertices = self.identify_landmark_vertices(vertices)\n","        importance = self.compute_vertex_importance(vertices, faces, normals)\n","\n","        # Convert encrypted data to bit array\n","        bit_array = ''.join(format(byte, '08b') for byte in encrypted_data)\n","\n","        # Check if the message is too large\n","        if len(bit_array) > len(landmark_vertices):\n","            raise ValueError(f\"Message too large for this face model. Message bits: {len(bit_array)}, Available vertices: {len(landmark_vertices)}\")\n","\n","        # Embed data in vertices near landmarks using rounding and a larger scale factor\n","        for i, bit in enumerate(bit_array):\n","            vertex_idx = landmark_vertices[i]\n","            scale_factor = 0.001 * (1 - importance[vertex_idx])  # Significantly increased scale_factor\n","\n","            # Apply rounding to the modification\n","            modification = round(float(bit) * scale_factor, 6)  # Round to 6 decimal places\n","\n","            vertices[vertex_idx] += modification * normals[vertex_idx]\n","\n","        face_model['vertices'] = vertices\n","        return face_model\n","\n","    def extract_from_face_model(self, face_model, original_model, message_length):\n","        \"\"\"Extract encrypted data from modified 3D face model\"\"\"\n","        modified_vertices = face_model['vertices']\n","        original_vertices = original_model['vertices']\n","        landmark_vertices = self.identify_landmark_vertices(original_vertices)\n","\n","        bits = []\n","        for i in range(message_length * 8):  # Iterate over the expected number of bits\n","            if i >= len(landmark_vertices):\n","                print(f\"Warning: Not enough landmark vertices to extract the full message. Extracted {i} bits, expected {message_length * 8} bits.\")\n","                break  # Stop if we run out of landmark vertices\n","            vertex_idx = landmark_vertices[i]\n","\n","            # Compare modified vertex with original\n","            diff = modified_vertices[vertex_idx] - original_vertices[vertex_idx]\n","            # Extract bit based on vertex displacement using a tolerance\n","\n","            extracted_bit = np.dot(diff, original_model['normals'][vertex_idx]) #Using original normals\n","\n","            #Using tolerance instead of direct comparison with 0\n","            bit = '1' if extracted_bit > 1e-6 else '0'\n","            bits.append(bit)\n","\n","        # Convert bits back to bytes\n","        extracted_data = bytes(\n","            int(''.join(bits[i:i + 8]), 2) for i in range(0, len(bits), 8)\n","        )\n","\n","        return extracted_data\n"]},{"cell_type":"code","source":[],"metadata":{"id":"WCgO7nc-4ijn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d7115ef7-1327-4d84-bd34-2dc2f6274bec","executionInfo":{"status":"ok","timestamp":1736792326169,"user_tz":-300,"elapsed":17056,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"id":"fFAwWKgu3MyQ"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generated passphrase: IRyZX3vV9vg1M%VSkVBiHDyPhL#euGm@\n","Original message: short\n","Decrypted message: short\n"]}],"source":["def main():\n","    # Initialize steganography system\n","    stego = SecureFaceSteganography()\n","\n","    # Load 3D face model (example path)\n","    face_model = stego.load_face_model('/content/drive/MyDrive/OutputPaper2/15807_Zombie_Hand_v1_NEW.obj')\n","    original_model = {key: value.copy() for key, value in face_model.items()}\n","\n","    # Generate secure passphrase\n","    passphrase = stego.generate_passphrase()\n","    print(f\"Generated passphrase: {passphrase}\")\n","\n","    # Message to hide - Reduced length to fit within the model's capacity\n","    secret_message = \"short\"\n","\n","    # Encrypt the message\n","    encrypted_data = stego.encrypt_message(secret_message, passphrase)\n","\n","    # Embed encrypted data in face model\n","    modified_model = stego.embed_in_face_model(face_model, encrypted_data)\n","\n","    # Extract and decrypt\n","    extracted_data = stego.extract_from_face_model(\n","        modified_model, original_model, len(encrypted_data)\n","    )\n","    decrypted_message = stego.decrypt_message(extracted_data, passphrase)\n","\n","    print(f\"Original message: {secret_message}\")\n","    print(f\"Decrypted message: {decrypted_message}\")\n","\n","    # Save modified model\n","    mesh = trimesh.Trimesh(\n","        vertices=modified_model['vertices'],\n","        faces=modified_model['faces']\n","    )\n","    mesh.export('/content/drive/MyDrive/OutputPaper2/modified_15807_Zombie_Hand_v1_NEW.obj')\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","source":["Evaluation for 15807_Zombie_Hand_v1_NEW"],"metadata":{"id":"UxYUH4473ZzO"}},{"source":["#!pip install pyglet\n","#!pip install pyglet<2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error\n","import trimesh\n","from scipy.stats import wasserstein_distance\n","from skimage.metrics import structural_similarity\n","import math\n","from scipy.spatial import KDTree\n","import os\n","\n","class Stego3DEvaluator:\n","    def __init__(self):\n","        \"\"\"Initialize the 3D steganography evaluator\"\"\"\n","        self.metrics = {}\n","\n","    def preprocess_models(self, original_mesh, stego_mesh):\n","        \"\"\"Preprocess and align models to ensure compatibility\"\"\"\n","        # Center both meshes\n","        original_mesh.vertices -= original_mesh.vertices.mean(axis=0)\n","        stego_mesh.vertices -= stego_mesh.vertices.mean(axis=0)\n","\n","        # Scale to unit cube\n","        original_scale = np.max(np.abs(original_mesh.vertices))\n","        stego_scale = np.max(np.abs(stego_mesh.vertices))\n","\n","        original_mesh.vertices /= original_scale\n","        stego_mesh.vertices /= stego_scale\n","\n","        return original_mesh, stego_mesh\n","\n","    def align_vertices(self, original_vertices, stego_vertices):\n","        \"\"\"Align vertices between models using nearest neighbor matching\"\"\"\n","        # Build KD-tree for faster nearest neighbor search\n","        tree = KDTree(original_vertices)\n","\n","        # Find nearest neighbors for each stego vertex\n","        distances, indices = tree.query(stego_vertices)\n","\n","        # Create aligned vertex arrays\n","        aligned_original = original_vertices[indices]\n","        aligned_stego = stego_vertices\n","\n","        return aligned_original, aligned_stego, distances\n","\n","    def load_models(self, original_path, stego_path, align=True):\n","        \"\"\"Load and preprocess original and stego 3D models\"\"\"\n","        try:\n","            # Load meshes\n","            original_mesh = trimesh.load(original_path)\n","            stego_mesh = trimesh.load(stego_path)\n","\n","            # Check if loaded data is a Scene and extract the first mesh if it is\n","            if isinstance(original_mesh, trimesh.Scene):\n","                original_mesh = next(iter(original_mesh.geometry.values())) # Get the first mesh from the scene\n","            if isinstance(stego_mesh, trimesh.Scene):\n","                stego_mesh = next(iter(stego_mesh.geometry.values())) # Get the first mesh from the scene\n","\n","            print(f\"Original vertices: {len(original_mesh.vertices)}\")\n","            print(f\"Stego vertices: {len(stego_mesh.vertices)}\")\n","\n","            # Preprocess meshes\n","            original_mesh, stego_mesh = self.preprocess_models(original_mesh, stego_mesh)\n","\n","            if align:\n","                # Align vertices\n","                self.original_vertices, self.stego_vertices, distances = self.align_vertices(\n","                    original_mesh.vertices,\n","                    stego_mesh.vertices\n","                )\n","\n","                # Print alignment statistics\n","                print(f\"\\nAlignment Statistics:\")\n","                print(f\"Mean distance: {np.mean(distances):.6f}\")\n","                print(f\"Max distance: {np.max(distances):.6f}\")\n","                print(f\"Aligned vertices: {len(self.original_vertices)}\")\n","            else:\n","                if len(original_mesh.vertices) != len(stego_mesh.vertices):\n","                    raise ValueError(\"Models have different number of vertices and alignment is disabled\")\n","                self.original_vertices = original_mesh.vertices\n","                self.stego_vertices = stego_mesh.vertices\n","\n","            self.original_mesh = original_mesh\n","            self.stego_mesh = stego_mesh\n","\n","            return True\n","\n","        except Exception as e:\n","            print(f\"Error loading models: {str(e)}\")\n","            return False\n","\n","    def calculate_vertex_error_map(self):\n","        \"\"\"Calculate and visualize vertex-wise errors\"\"\"\n","        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n","        return errors\n","\n","\n","\n","    def calculate_psnr(self):\n","        \"\"\"Calculate Peak Signal-to-Noise Ratio\"\"\"\n","        mse = np.mean((self.original_vertices - self.stego_vertices) ** 2)\n","        if mse == 0:\n","            return float('inf')\n","\n","        max_val = np.max(self.original_vertices) - np.min(self.original_vertices)\n","        psnr = 20 * math.log10(max_val / math.sqrt(mse))\n","        self.metrics['PSNR'] = psnr\n","        return psnr\n","\n","    def calculate_ssim(self):\n","        \"\"\"Calculate Structural Similarity Index\"\"\"\n","        orig_reshaped = self.original_vertices.reshape(-1, 3)\n","        stego_reshaped = self.stego_vertices.reshape(-1, 3)\n","\n","        ssim_scores = []\n","        for i in range(3):\n","            score = structural_similarity(\n","                orig_reshaped[:, i],\n","                stego_reshaped[:, i],\n","                data_range=np.max(orig_reshaped[:, i]) - np.min(orig_reshaped[:, i])\n","            )\n","            ssim_scores.append(score)\n","\n","        ssim = np.mean(ssim_scores)\n","        self.metrics['SSIM'] = ssim\n","        return ssim\n","\n","    def calculate_mse(self):\n","        \"\"\"Calculate Mean Squared Error\"\"\"\n","        mse = mean_squared_error(self.original_vertices, self.stego_vertices)\n","        self.metrics['MSE'] = mse\n","        return mse\n","\n","    def calculate_rmse(self):\n","        \"\"\"Calculate Root Mean Squared Error\"\"\"\n","        rmse = np.sqrt(self.calculate_mse())\n","        self.metrics['RMSE'] = rmse\n","        return rmse\n","\n","    def calculate_ber(self, threshold=1e-6):\n","        \"\"\"Calculate Bit Error Rate\"\"\"\n","        differences = np.abs(self.original_vertices - self.stego_vertices)\n","        binary_orig = (self.original_vertices > threshold).astype(int)\n","        binary_stego = (self.stego_vertices > threshold).astype(int)\n","\n","        total_bits = np.prod(binary_orig.shape)\n","        error_bits = np.sum(binary_orig != binary_stego)\n","\n","        ber = error_bits / total_bits\n","        self.metrics['BER'] = ber\n","        return ber\n","\n","    def calculate_hausdorff_distance(self):\n","        \"\"\"Calculate Hausdorff distance between original and stego models\"\"\"\n","        def directed_hausdorff(source, target):\n","            tree = KDTree(target)\n","            distances, _ = tree.query(source)\n","            return np.max(distances)\n","\n","        forward = directed_hausdorff(self.original_vertices, self.stego_vertices)\n","        backward = directed_hausdorff(self.stego_vertices, self.original_vertices)\n","\n","        hausdorff = max(forward, backward)\n","        self.metrics['Hausdorff'] = hausdorff\n","        return hausdorff\n","\n","    def calculate_histogram_similarity(self, bins=50):\n","        \"\"\"Calculate histogram similarity using Wasserstein distance\"\"\"\n","        distances = []\n","\n","        for i in range(3):\n","            hist_orig, _ = np.histogram(self.original_vertices[:, i], bins=bins, density=True)\n","            hist_stego, _ = np.histogram(self.stego_vertices[:, i], bins=bins, density=True)\n","\n","            distance = wasserstein_distance(hist_orig, hist_stego)\n","            distances.append(distance)\n","\n","        hist_similarity = 1 / (1 + np.mean(distances))\n","        self.metrics['Histogram_Similarity'] = hist_similarity\n","        return hist_similarity\n","\n","    def plot_histograms(self, save_path=None):\n","        \"\"\"Plot histograms of original and stego models\"\"\"\n","        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","        coords = ['X', 'Y', 'Z']\n","\n","        for i, (ax, coord) in enumerate(zip(axes, coords)):\n","            ax.hist(self.original_vertices[:, i], bins=50, alpha=0.5, label='Original', density=True)\n","            ax.hist(self.stego_vertices[:, i], bins=50, alpha=0.5, label='Stego', density=True)\n","            ax.set_title(f'{coord} Coordinate Distribution')\n","            ax.set_xlabel(f'{coord} Value')\n","            ax.set_ylabel('Density')\n","            ax.legend()\n","\n","        plt.tight_layout()\n","        if save_path:\n","            plt.savefig(save_path)\n","            plt.close()\n","        else:\n","            plt.show()\n","\n","    def plot_error_distribution(self, save_path=None):\n","        \"\"\"Plot the distribution of geometric errors\"\"\"\n","        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n","\n","        plt.figure(figsize=(10, 6))\n","        plt.hist(errors, bins=50, density=True)\n","        plt.title('Geometric Error Distribution')\n","        plt.xlabel('Error Magnitude')\n","        plt.ylabel('Density')\n","\n","        if save_path:\n","            plt.savefig(save_path)\n","            plt.close()\n","        else:\n","            plt.show()\n","\n","    def evaluate_all(self, plot=True, save_plots=False):\n","        \"\"\"Calculate all metrics and optionally generate plots\"\"\"\n","        metrics = {\n","            'PSNR': self.calculate_psnr(),\n","            'SSIM': self.calculate_ssim(),\n","            'MSE': self.calculate_mse(),\n","            'RMSE': self.calculate_rmse(),\n","            'BER': self.calculate_ber(),\n","            'Hausdorff': self.calculate_hausdorff_distance(),\n","            'Histogram_Similarity': self.calculate_histogram_similarity()\n","        }\n","\n","        if plot:\n","            self.plot_histograms(save_path='/content/drive/MyDrive/OutputPaper2/histograms_15807_Zombie_Hand_v1_NEW_.png' if save_plots else None)\n","            self.plot_error_distribution(save_path='/content/drive/MyDrive/OutputPaper2/error_distribution_15807_Zombie_Hand_v1_NEW.png' if save_plots else None)\n","            #self.visualize_error_map(save_path='error_map.png' if save_plots else None)\n","\n","        return metrics\n","    def generate_report(self, output_path='/content/drive/MyDrive/OutputPaper2/evaluation_report_15807_Zombie_Hand_v1_NEW.txt'):\n","        \"\"\"Generate a detailed evaluation report\"\"\"\n","        with open(output_path, 'w') as f:\n","            f.write(\"3D Steganography Evaluation Report\\n\")\n","            f.write(\"=================================\\n\\n\")\n","\n","            # Model information\n","            f.write(\"Model Information:\\n\")\n","            f.write(f\"Number of vertices: {len(self.original_vertices)}\\n\")\n","            f.write(f\"Number of faces: {len(self.original_mesh.faces)}\\n\\n\")\n","\n","            # Metrics\n","            f.write(\"Quality Metrics:\\n\")\n","            for metric, value in self.metrics.items():\n","                f.write(f\"{metric}: {value:.6f}\\n\")\n","\n","            f.write(\"\\nInterpretation:\\n\")\n","            f.write(\"- PSNR > 30 dB typically indicates good quality\\n\")\n","            f.write(\"- SSIM closer to 1 indicates better structural preservation\\n\")\n","            f.write(\"- Lower MSE and RMSE values indicate better similarity\\n\")\n","            f.write(\"- Lower BER indicates better steganographic accuracy\\n\")\n","            f.write(\"- Histogram similarity closer to 1 indicates better statistical imperceptibility\\n\")\n","\n","def main():\n","    # Initialize evaluator\n","    evaluator = Stego3DEvaluator()\n","\n","    # Load and align models\n","    if not evaluator.load_models('/content/drive/MyDrive/OutputPaper2/modified_15807_Zombie_Hand_v1_NEW.obj', '/content/drive/MyDrive/OutputPaper2/15807_Zombie_Hand_v1_NEW.obj', align=True):\n","        return\n","\n","    # Perform evaluation\n","    metrics = evaluator.evaluate_all(plot=True, save_plots=True)\n","\n","    # Print results\n","    print(\"\\nEvaluation Results:\")\n","    for metric, value in metrics.items():\n","        print(f\"{metric}: {value:.6f}\")\n","    evaluator.generate_report()\n","    print(\"\\nDetailed report saved to '/content/drive/MyDrive/OutputPaper2/evaluation_report_15807_Zombie_Hand_v1_NEW.txt'\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736792417991,"user_tz":-300,"elapsed":3423,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"outputId":"affece4b-3bf7-4866-f6ed-333673a3f1d8","id":"H0P01AMt3YVo"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Original vertices: 17888\n","Stego vertices: 17961\n","\n","Alignment Statistics:\n","Mean distance: 0.002351\n","Max distance: 0.003575\n","Aligned vertices: 17961\n","\n","Evaluation Results:\n","PSNR: 59.764732\n","SSIM: 0.998935\n","MSE: 0.000002\n","RMSE: 0.001430\n","BER: 0.001466\n","Hausdorff: 0.003575\n","Histogram_Similarity: 0.984463\n","\n","Detailed report saved to '/content/drive/MyDrive/OutputPaper2/evaluation_report_15807_Zombie_Hand_v1_NEW.txt'\n"]}]},{"cell_type":"markdown","source":["Embedding for 15800_Mummy_Hand_v1_NEW"],"metadata":{"id":"gZ7rdFhd5wTl"}},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"status":"ok","timestamp":1736792560326,"user_tz":-300,"elapsed":953,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"id":"742qgD435uhM"},"outputs":[],"source":["#!pip install pycryptodome\n","#!pip install trimesh\n","import numpy as np\n","from Crypto.Cipher import AES\n","from Crypto.Util.Padding import pad, unpad\n","import hashlib\n","import secrets\n","import struct\n","import trimesh\n","import scipy.spatial as spatial\n","\n","class SecureFaceSteganography:\n","    def __init__(self):\n","        # ... (other code)\n","        self.LANDMARK_REGIONS = {\n","            'forehead': [(0.2, 0.8, 0.5), (0.8, 0.8, 0.5)],  # Wider bounding box\n","            'cheeks': [(0.1, 0.5, 0.5), (0.9, 0.5, 0.5)],  # Wider bounding box\n","            'jaw': [(0.2, 0.2, 0.5), (0.8, 0.2, 0.5)],  # Wider bounding box\n","            'nose': [(0.4, 0.6, 0.5), (0.6, 0.6, 0.5)],  # Added nose region\n","            'chin': [(0.5, 0.1, 0.5)]  #chin region\n","        }\n","        # Define SALT_SIZE and BLOCK_SIZE in the __init__ method\n","        self.SALT_SIZE = 16  # 128 bits for salt\n","        self.BLOCK_SIZE = 16 # 128 bits for block size\n","        self.distributed_landmarks = None  # Initialize distributed_landmarks\n","\n","    def load_face_model(self, file_path):\n","        \"\"\"Load 3D face model and prepare it for steganography\"\"\"\n","        try:\n","            loaded_data = trimesh.load(file_path)\n","            # Check if loaded_data is a Scene and extract the first mesh if it is\n","            if isinstance(loaded_data, trimesh.Scene):\n","                mesh = next(iter(loaded_data.geometry.values())) # Get the first mesh from the scene\n","            else:\n","                mesh = loaded_data\n","\n","            return {\n","                'vertices': np.array(mesh.vertices),\n","                'faces': np.array(mesh.faces),\n","                'normals': np.array(mesh.vertex_normals)\n","            }\n","        except Exception as e:\n","            raise ValueError(f\"Error loading face model: {str(e)}\")\n","\n","    def identify_landmark_vertices(self, vertices, landmark_regions=None):\n","        if landmark_regions is None:\n","            landmark_regions = self.LANDMARK_REGIONS\n","\n","        # Use stored landmarks if available, otherwise generate\n","        if self.distributed_landmarks is None:\n","            num_landmarks = min(1000, len(vertices))\n","            self.distributed_landmarks = np.random.choice(len(vertices), num_landmarks, replace=False)\n","\n","        return sorted(self.distributed_landmarks)  # Return stored landmarks\n","\n","    def compute_vertex_importance(self, vertices, faces, normals):\n","        \"\"\"Compute vertex importance based on geometric features\"\"\"\n","        importance = np.zeros(len(vertices))\n","\n","        # Calculate curvature (simplified)\n","        for i, vertex in enumerate(vertices):\n","            # Find connected vertices\n","            connected = faces[np.any(faces == i, axis=1)]\n","            connected = np.unique(connected.flatten())\n","            connected = connected[connected != i]\n","\n","            # Calculate local curvature\n","            if len(connected) > 0:\n","                connected_vertices = vertices[connected]\n","                mean_position = np.mean(connected_vertices, axis=0)\n","                displacement = np.linalg.norm(vertex - mean_position)\n","                importance[i] = displacement\n","\n","        return importance\n","\n","    def generate_passphrase(self, length=32):\n","        \"\"\"Generate a cryptographically secure random passphrase\"\"\"\n","        charset = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&*\"\n","        return ''.join(secrets.choice(charset) for _ in range(length))\n","\n","    def derive_key(self, passphrase, salt):\n","        \"\"\"Derive encryption key using SHA-256 with salt\"\"\"\n","        key_material = hashlib.sha256()\n","        key_material.update(passphrase.encode('utf-8'))\n","        key_material.update(salt)\n","        return key_material.digest()\n","\n","    def encrypt_message(self, message, passphrase):\n","        \"\"\"Encrypt a message using AES-128-CBC with secure key derivation\"\"\"\n","        salt = secrets.token_bytes(self.SALT_SIZE)\n","        key = self.derive_key(passphrase, salt)\n","        iv = secrets.token_bytes(self.BLOCK_SIZE)\n","\n","        cipher = AES.new(key, AES.MODE_CBC, iv)\n","        padded_data = pad(message.encode('utf-8'), self.BLOCK_SIZE)\n","        ciphertext = cipher.encrypt(padded_data)\n","\n","        return salt + iv + ciphertext\n","\n","    def decrypt_message(self, encrypted_data, passphrase):\n","        \"\"\"Decrypt a message using AES-128-CBC\"\"\"\n","        salt = encrypted_data[:self.SALT_SIZE]\n","        iv = encrypted_data[self.SALT_SIZE:self.SALT_SIZE + self.BLOCK_SIZE]\n","        ciphertext = encrypted_data[self.SALT_SIZE + self.BLOCK_SIZE:]\n","\n","        key = self.derive_key(passphrase, salt)\n","        cipher = AES.new(key, AES.MODE_CBC, iv)\n","\n","        # Attempt to decrypt. Handle potential padding errors\n","        try:\n","            padded_message = cipher.decrypt(ciphertext)\n","            return unpad(padded_message, self.BLOCK_SIZE).decode('utf-8')\n","        except ValueError:\n","            print(\"Warning: Decryption failed. Possible data corruption or incorrect passphrase.\")\n","            return None  # or raise a more specific exception\n","\n","\n","    def embed_in_face_model(self, face_model, encrypted_data):\n","        \"\"\"Embed encrypted data in 3D face model using geometric features\"\"\"\n","        vertices = face_model['vertices'].copy()\n","        faces = face_model['faces']\n","        normals = face_model['normals']\n","\n","        # Get landmarks and importance metrics\n","        landmark_vertices = self.identify_landmark_vertices(vertices)\n","        importance = self.compute_vertex_importance(vertices, faces, normals)\n","\n","        # Convert encrypted data to bit array\n","        bit_array = ''.join(format(byte, '08b') for byte in encrypted_data)\n","\n","        # Check if the message is too large\n","        if len(bit_array) > len(landmark_vertices):\n","            raise ValueError(f\"Message too large for this face model. Message bits: {len(bit_array)}, Available vertices: {len(landmark_vertices)}\")\n","\n","        # Embed data in vertices near landmarks using rounding and a larger scale factor\n","        for i, bit in enumerate(bit_array):\n","            vertex_idx = landmark_vertices[i]\n","            scale_factor = 0.001 * (1 - importance[vertex_idx])  # Significantly increased scale_factor\n","\n","            # Apply rounding to the modification\n","            modification = round(float(bit) * scale_factor, 6)  # Round to 6 decimal places\n","\n","            vertices[vertex_idx] += modification * normals[vertex_idx]\n","\n","        face_model['vertices'] = vertices\n","        return face_model\n","\n","    def extract_from_face_model(self, face_model, original_model, message_length):\n","        \"\"\"Extract encrypted data from modified 3D face model\"\"\"\n","        modified_vertices = face_model['vertices']\n","        original_vertices = original_model['vertices']\n","        landmark_vertices = self.identify_landmark_vertices(original_vertices)\n","\n","        bits = []\n","        for i in range(message_length * 8):  # Iterate over the expected number of bits\n","            if i >= len(landmark_vertices):\n","                print(f\"Warning: Not enough landmark vertices to extract the full message. Extracted {i} bits, expected {message_length * 8} bits.\")\n","                break  # Stop if we run out of landmark vertices\n","            vertex_idx = landmark_vertices[i]\n","\n","            # Compare modified vertex with original\n","            diff = modified_vertices[vertex_idx] - original_vertices[vertex_idx]\n","            # Extract bit based on vertex displacement using a tolerance\n","\n","            extracted_bit = np.dot(diff, original_model['normals'][vertex_idx]) #Using original normals\n","\n","            #Using tolerance instead of direct comparison with 0\n","            bit = '1' if extracted_bit > 1e-6 else '0'\n","            bits.append(bit)\n","\n","        # Convert bits back to bytes\n","        extracted_data = bytes(\n","            int(''.join(bits[i:i + 8]), 2) for i in range(0, len(bits), 8)\n","        )\n","\n","        return extracted_data\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ed0bef07-e507-4a62-85e0-5d343441666d","executionInfo":{"status":"ok","timestamp":1736792699637,"user_tz":-300,"elapsed":119725,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"id":"OALnAt0w5kQt"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generated passphrase: a2LK6QRjf*dF06fZFt3iEC@r0ncxvxxd\n","Original message: short\n","Decrypted message: short\n"]}],"source":["def main():\n","    # Initialize steganography system\n","    stego = SecureFaceSteganography()\n","\n","    # Load 3D face model (example path)\n","    face_model = stego.load_face_model('/content/drive/MyDrive/OutputPaper2/15800_Mummy_Hand_v1_NEW.obj')\n","    original_model = {key: value.copy() for key, value in face_model.items()}\n","\n","    # Generate secure passphrase\n","    passphrase = stego.generate_passphrase()\n","    print(f\"Generated passphrase: {passphrase}\")\n","\n","    # Message to hide - Reduced length to fit within the model's capacity\n","    secret_message = \"short\"\n","\n","    # Encrypt the message\n","    encrypted_data = stego.encrypt_message(secret_message, passphrase)\n","\n","    # Embed encrypted data in face model\n","    modified_model = stego.embed_in_face_model(face_model, encrypted_data)\n","\n","    # Extract and decrypt\n","    extracted_data = stego.extract_from_face_model(\n","        modified_model, original_model, len(encrypted_data)\n","    )\n","    decrypted_message = stego.decrypt_message(extracted_data, passphrase)\n","\n","    print(f\"Original message: {secret_message}\")\n","    print(f\"Decrypted message: {decrypted_message}\")\n","\n","    # Save modified model\n","    mesh = trimesh.Trimesh(\n","        vertices=modified_model['vertices'],\n","        faces=modified_model['faces']\n","    )\n","    mesh.export('/content/drive/MyDrive/OutputPaper2/modified_15800_Mummy_Hand_v1_NEW.obj')\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","source":["Embedding for 15742_Zombie_Arm_v1"],"metadata":{"id":"0LwdcT8S8UTk"}},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"02ecb2e5-7bc4-4f12-9471-0c5b9d3fb898","executionInfo":{"status":"ok","timestamp":1736793039483,"user_tz":-300,"elapsed":70255,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"id":"IFkMLBUM7Q_h"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generated passphrase: 9V*WqD9wznH*Lqu!z&D4IY3AGzY7bWhS\n","Original message: short\n","Decrypted message: short\n"]}],"source":["def main():\n","    # Initialize steganography system\n","    stego = SecureFaceSteganography()\n","\n","    # Load 3D face model (example path)\n","    face_model = stego.load_face_model('/content/drive/MyDrive/OutputPaper2/15742_Zombie_Arm_v1.obj')\n","    original_model = {key: value.copy() for key, value in face_model.items()}\n","\n","    # Generate secure passphrase\n","    passphrase = stego.generate_passphrase()\n","    print(f\"Generated passphrase: {passphrase}\")\n","\n","    # Message to hide - Reduced length to fit within the model's capacity\n","    secret_message = \"short\"\n","\n","    # Encrypt the message\n","    encrypted_data = stego.encrypt_message(secret_message, passphrase)\n","\n","    # Embed encrypted data in face model\n","    modified_model = stego.embed_in_face_model(face_model, encrypted_data)\n","\n","    # Extract and decrypt\n","    extracted_data = stego.extract_from_face_model(\n","        modified_model, original_model, len(encrypted_data)\n","    )\n","    decrypted_message = stego.decrypt_message(extracted_data, passphrase)\n","\n","    print(f\"Original message: {secret_message}\")\n","    print(f\"Decrypted message: {decrypted_message}\")\n","\n","    # Save modified model\n","    mesh = trimesh.Trimesh(\n","        vertices=modified_model['vertices'],\n","        faces=modified_model['faces']\n","    )\n","    mesh.export('/content/drive/MyDrive/OutputPaper2/modified_15742_Zombie_Arm_v1.obj')\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","source":[],"metadata":{"id":"Wp2EB8Ni8Z1F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Embedding for 16794_Harpy_V1"],"metadata":{"id":"EeOmulIX8bjI"}},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"282a3f08-002e-4fdf-814c-3dd294ae46e5","executionInfo":{"status":"ok","timestamp":1736793494511,"user_tz":-300,"elapsed":213972,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"id":"xFzNgxfR8akD"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generated passphrase: BOF7eU5RoaSkGM1#*GkEZuY#imOTaJyl\n","Original message: short\n","Decrypted message: short\n"]}],"source":["def main():\n","    # Initialize steganography system\n","    stego = SecureFaceSteganography()\n","\n","    # Load 3D face model (example path)\n","    face_model = stego.load_face_model('/content/drive/MyDrive/OutputPaper2/16794_Harpy_V1.obj')\n","    original_model = {key: value.copy() for key, value in face_model.items()}\n","\n","    # Generate secure passphrase\n","    passphrase = stego.generate_passphrase()\n","    print(f\"Generated passphrase: {passphrase}\")\n","\n","    # Message to hide - Reduced length to fit within the model's capacity\n","    secret_message = \"short\"\n","\n","    # Encrypt the message\n","    encrypted_data = stego.encrypt_message(secret_message, passphrase)\n","\n","    # Embed encrypted data in face model\n","    modified_model = stego.embed_in_face_model(face_model, encrypted_data)\n","\n","    # Extract and decrypt\n","    extracted_data = stego.extract_from_face_model(\n","        modified_model, original_model, len(encrypted_data)\n","    )\n","    decrypted_message = stego.decrypt_message(extracted_data, passphrase)\n","\n","    print(f\"Original message: {secret_message}\")\n","    print(f\"Decrypted message: {decrypted_message}\")\n","\n","    # Save modified model\n","    mesh = trimesh.Trimesh(\n","        vertices=modified_model['vertices'],\n","        faces=modified_model['faces']\n","    )\n","    mesh.export('/content/drive/MyDrive/OutputPaper2/modified_16794_Harpy_V1.obj')\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"markdown","source":["Evaluation for 15800_Mummy_Hand_v1_NEW"],"metadata":{"id":"qwMbgfrs5YsM"}},{"source":["#!pip install pyglet\n","#!pip install pyglet<2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error\n","import trimesh\n","from scipy.stats import wasserstein_distance\n","from skimage.metrics import structural_similarity\n","import math\n","from scipy.spatial import KDTree\n","import os\n","\n","class Stego3DEvaluator:\n","    def __init__(self):\n","        \"\"\"Initialize the 3D steganography evaluator\"\"\"\n","        self.metrics = {}\n","\n","    def preprocess_models(self, original_mesh, stego_mesh):\n","        \"\"\"Preprocess and align models to ensure compatibility\"\"\"\n","        # Center both meshes\n","        original_mesh.vertices -= original_mesh.vertices.mean(axis=0)\n","        stego_mesh.vertices -= stego_mesh.vertices.mean(axis=0)\n","\n","        # Scale to unit cube\n","        original_scale = np.max(np.abs(original_mesh.vertices))\n","        stego_scale = np.max(np.abs(stego_mesh.vertices))\n","\n","        original_mesh.vertices /= original_scale\n","        stego_mesh.vertices /= stego_scale\n","\n","        return original_mesh, stego_mesh\n","\n","    def align_vertices(self, original_vertices, stego_vertices):\n","        \"\"\"Align vertices between models using nearest neighbor matching\"\"\"\n","        # Build KD-tree for faster nearest neighbor search\n","        tree = KDTree(original_vertices)\n","\n","        # Find nearest neighbors for each stego vertex\n","        distances, indices = tree.query(stego_vertices)\n","\n","        # Create aligned vertex arrays\n","        aligned_original = original_vertices[indices]\n","        aligned_stego = stego_vertices\n","\n","        return aligned_original, aligned_stego, distances\n","\n","    def load_models(self, original_path, stego_path, align=True):\n","        \"\"\"Load and preprocess original and stego 3D models\"\"\"\n","        try:\n","            # Load meshes\n","            original_mesh = trimesh.load(original_path)\n","            stego_mesh = trimesh.load(stego_path)\n","\n","            # Check if loaded data is a Scene and extract the first mesh if it is\n","            if isinstance(original_mesh, trimesh.Scene):\n","                original_mesh = next(iter(original_mesh.geometry.values())) # Get the first mesh from the scene\n","            if isinstance(stego_mesh, trimesh.Scene):\n","                stego_mesh = next(iter(stego_mesh.geometry.values())) # Get the first mesh from the scene\n","\n","            print(f\"Original vertices: {len(original_mesh.vertices)}\")\n","            print(f\"Stego vertices: {len(stego_mesh.vertices)}\")\n","\n","            # Preprocess meshes\n","            original_mesh, stego_mesh = self.preprocess_models(original_mesh, stego_mesh)\n","\n","            if align:\n","                # Align vertices\n","                self.original_vertices, self.stego_vertices, distances = self.align_vertices(\n","                    original_mesh.vertices,\n","                    stego_mesh.vertices\n","                )\n","\n","                # Print alignment statistics\n","                print(f\"\\nAlignment Statistics:\")\n","                print(f\"Mean distance: {np.mean(distances):.6f}\")\n","                print(f\"Max distance: {np.max(distances):.6f}\")\n","                print(f\"Aligned vertices: {len(self.original_vertices)}\")\n","            else:\n","                if len(original_mesh.vertices) != len(stego_mesh.vertices):\n","                    raise ValueError(\"Models have different number of vertices and alignment is disabled\")\n","                self.original_vertices = original_mesh.vertices\n","                self.stego_vertices = stego_mesh.vertices\n","\n","            self.original_mesh = original_mesh\n","            self.stego_mesh = stego_mesh\n","\n","            return True\n","\n","        except Exception as e:\n","            print(f\"Error loading models: {str(e)}\")\n","            return False\n","\n","    def calculate_vertex_error_map(self):\n","        \"\"\"Calculate and visualize vertex-wise errors\"\"\"\n","        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n","        return errors\n","\n","\n","\n","    def calculate_psnr(self):\n","        \"\"\"Calculate Peak Signal-to-Noise Ratio\"\"\"\n","        mse = np.mean((self.original_vertices - self.stego_vertices) ** 2)\n","        if mse == 0:\n","            return float('inf')\n","\n","        max_val = np.max(self.original_vertices) - np.min(self.original_vertices)\n","        psnr = 20 * math.log10(max_val / math.sqrt(mse))\n","        self.metrics['PSNR'] = psnr\n","        return psnr\n","\n","    def calculate_ssim(self):\n","        \"\"\"Calculate Structural Similarity Index\"\"\"\n","        orig_reshaped = self.original_vertices.reshape(-1, 3)\n","        stego_reshaped = self.stego_vertices.reshape(-1, 3)\n","\n","        ssim_scores = []\n","        for i in range(3):\n","            score = structural_similarity(\n","                orig_reshaped[:, i],\n","                stego_reshaped[:, i],\n","                data_range=np.max(orig_reshaped[:, i]) - np.min(orig_reshaped[:, i])\n","            )\n","            ssim_scores.append(score)\n","\n","        ssim = np.mean(ssim_scores)\n","        self.metrics['SSIM'] = ssim\n","        return ssim\n","\n","    def calculate_mse(self):\n","        \"\"\"Calculate Mean Squared Error\"\"\"\n","        mse = mean_squared_error(self.original_vertices, self.stego_vertices)\n","        self.metrics['MSE'] = mse\n","        return mse\n","\n","    def calculate_rmse(self):\n","        \"\"\"Calculate Root Mean Squared Error\"\"\"\n","        rmse = np.sqrt(self.calculate_mse())\n","        self.metrics['RMSE'] = rmse\n","        return rmse\n","\n","    def calculate_ber(self, threshold=1e-6):\n","        \"\"\"Calculate Bit Error Rate\"\"\"\n","        differences = np.abs(self.original_vertices - self.stego_vertices)\n","        binary_orig = (self.original_vertices > threshold).astype(int)\n","        binary_stego = (self.stego_vertices > threshold).astype(int)\n","\n","        total_bits = np.prod(binary_orig.shape)\n","        error_bits = np.sum(binary_orig != binary_stego)\n","\n","        ber = error_bits / total_bits\n","        self.metrics['BER'] = ber\n","        return ber\n","\n","    def calculate_hausdorff_distance(self):\n","        \"\"\"Calculate Hausdorff distance between original and stego models\"\"\"\n","        def directed_hausdorff(source, target):\n","            tree = KDTree(target)\n","            distances, _ = tree.query(source)\n","            return np.max(distances)\n","\n","        forward = directed_hausdorff(self.original_vertices, self.stego_vertices)\n","        backward = directed_hausdorff(self.stego_vertices, self.original_vertices)\n","\n","        hausdorff = max(forward, backward)\n","        self.metrics['Hausdorff'] = hausdorff\n","        return hausdorff\n","\n","    def calculate_histogram_similarity(self, bins=50):\n","        \"\"\"Calculate histogram similarity using Wasserstein distance\"\"\"\n","        distances = []\n","\n","        for i in range(3):\n","            hist_orig, _ = np.histogram(self.original_vertices[:, i], bins=bins, density=True)\n","            hist_stego, _ = np.histogram(self.stego_vertices[:, i], bins=bins, density=True)\n","\n","            distance = wasserstein_distance(hist_orig, hist_stego)\n","            distances.append(distance)\n","\n","        hist_similarity = 1 / (1 + np.mean(distances))\n","        self.metrics['Histogram_Similarity'] = hist_similarity\n","        return hist_similarity\n","\n","    def plot_histograms(self, save_path=None):\n","        \"\"\"Plot histograms of original and stego models\"\"\"\n","        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","        coords = ['X', 'Y', 'Z']\n","\n","        for i, (ax, coord) in enumerate(zip(axes, coords)):\n","            ax.hist(self.original_vertices[:, i], bins=50, alpha=0.5, label='Original', density=True)\n","            ax.hist(self.stego_vertices[:, i], bins=50, alpha=0.5, label='Stego', density=True)\n","            ax.set_title(f'{coord} Coordinate Distribution')\n","            ax.set_xlabel(f'{coord} Value')\n","            ax.set_ylabel('Density')\n","            ax.legend()\n","\n","        plt.tight_layout()\n","        if save_path:\n","            plt.savefig(save_path)\n","            plt.close()\n","        else:\n","            plt.show()\n","\n","    def plot_error_distribution(self, save_path=None):\n","        \"\"\"Plot the distribution of geometric errors\"\"\"\n","        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n","\n","        plt.figure(figsize=(10, 6))\n","        plt.hist(errors, bins=50, density=True)\n","        plt.title('Geometric Error Distribution')\n","        plt.xlabel('Error Magnitude')\n","        plt.ylabel('Density')\n","\n","        if save_path:\n","            plt.savefig(save_path)\n","            plt.close()\n","        else:\n","            plt.show()\n","\n","    def evaluate_all(self, plot=True, save_plots=False):\n","        \"\"\"Calculate all metrics and optionally generate plots\"\"\"\n","        metrics = {\n","            'PSNR': self.calculate_psnr(),\n","            'SSIM': self.calculate_ssim(),\n","            'MSE': self.calculate_mse(),\n","            'RMSE': self.calculate_rmse(),\n","            'BER': self.calculate_ber(),\n","            'Hausdorff': self.calculate_hausdorff_distance(),\n","            'Histogram_Similarity': self.calculate_histogram_similarity()\n","        }\n","\n","        if plot:\n","            self.plot_histograms(save_path='/content/drive/MyDrive/OutputPaper2/histograms_15800_Mummy_Hand_v1_NEW_.png' if save_plots else None)\n","            self.plot_error_distribution(save_path='/content/drive/MyDrive/OutputPaper2/error_distribution_15800_Mummy_Hand_v1_NEW.png' if save_plots else None)\n","            #self.visualize_error_map(save_path='error_map.png' if save_plots else None)\n","\n","        return metrics\n","    def generate_report(self, output_path='/content/drive/MyDrive/OutputPaper2/evaluation_report_15800_Mummy_Hand_v1_NEW.txt'):\n","        \"\"\"Generate a detailed evaluation report\"\"\"\n","        with open(output_path, 'w') as f:\n","            f.write(\"3D Steganography Evaluation Report\\n\")\n","            f.write(\"=================================\\n\\n\")\n","\n","            # Model information\n","            f.write(\"Model Information:\\n\")\n","            f.write(f\"Number of vertices: {len(self.original_vertices)}\\n\")\n","            f.write(f\"Number of faces: {len(self.original_mesh.faces)}\\n\\n\")\n","\n","            # Metrics\n","            f.write(\"Quality Metrics:\\n\")\n","            for metric, value in self.metrics.items():\n","                f.write(f\"{metric}: {value:.6f}\\n\")\n","\n","            f.write(\"\\nInterpretation:\\n\")\n","            f.write(\"- PSNR > 30 dB typically indicates good quality\\n\")\n","            f.write(\"- SSIM closer to 1 indicates better structural preservation\\n\")\n","            f.write(\"- Lower MSE and RMSE values indicate better similarity\\n\")\n","            f.write(\"- Lower BER indicates better steganographic accuracy\\n\")\n","            f.write(\"- Histogram similarity closer to 1 indicates better statistical imperceptibility\\n\")\n","\n","def main():\n","    # Initialize evaluator\n","    evaluator = Stego3DEvaluator()\n","\n","    # Load and align models\n","    if not evaluator.load_models('/content/drive/MyDrive/OutputPaper2/modified_15800_Mummy_Hand_v1_NEW.obj', '/content/drive/MyDrive/OutputPaper2/15800_Mummy_Hand_v1_NEW.obj', align=True):\n","        return\n","\n","    # Perform evaluation\n","    metrics = evaluator.evaluate_all(plot=True, save_plots=True)\n","\n","    # Print results\n","    print(\"\\nEvaluation Results:\")\n","    for metric, value in metrics.items():\n","        print(f\"{metric}: {value:.6f}\")\n","    evaluator.generate_report()\n","    print(\"\\nDetailed report saved to '/content/drive/MyDrive/OutputPaper2/evaluation_report_15800_Mummy_Hand_v1_NEW.txt'\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736792770223,"user_tz":-300,"elapsed":3423,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"outputId":"400294c8-f7b6-43a1-d569-1e4ebf17f51c","id":"Q9nZlAaZ5Xh4"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Original vertices: 48998\n","Stego vertices: 49098\n","\n","Alignment Statistics:\n","Mean distance: 0.001654\n","Max distance: 0.003119\n","Aligned vertices: 49098\n","\n","Evaluation Results:\n","PSNR: 64.761729\n","SSIM: 0.999883\n","MSE: 0.000001\n","RMSE: 0.001051\n","BER: 0.000401\n","Hausdorff: 0.003119\n","Histogram_Similarity: 0.996925\n","\n","Detailed report saved to '/content/drive/MyDrive/OutputPaper2/evaluation_report_15800_Mummy_Hand_v1_NEW.txt'\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"AODZKtBk73pV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluation for 15742_Zombie_Arm_v1"],"metadata":{"id":"z4e-cKC57448"}},{"source":["#!pip install pyglet\n","#!pip install pyglet<2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error\n","import trimesh\n","from scipy.stats import wasserstein_distance\n","from skimage.metrics import structural_similarity\n","import math\n","from scipy.spatial import KDTree\n","import os\n","\n","class Stego3DEvaluator:\n","    def __init__(self):\n","        \"\"\"Initialize the 3D steganography evaluator\"\"\"\n","        self.metrics = {}\n","\n","    def preprocess_models(self, original_mesh, stego_mesh):\n","        \"\"\"Preprocess and align models to ensure compatibility\"\"\"\n","        # Center both meshes\n","        original_mesh.vertices -= original_mesh.vertices.mean(axis=0)\n","        stego_mesh.vertices -= stego_mesh.vertices.mean(axis=0)\n","\n","        # Scale to unit cube\n","        original_scale = np.max(np.abs(original_mesh.vertices))\n","        stego_scale = np.max(np.abs(stego_mesh.vertices))\n","\n","        original_mesh.vertices /= original_scale\n","        stego_mesh.vertices /= stego_scale\n","\n","        return original_mesh, stego_mesh\n","\n","    def align_vertices(self, original_vertices, stego_vertices):\n","        \"\"\"Align vertices between models using nearest neighbor matching\"\"\"\n","        # Build KD-tree for faster nearest neighbor search\n","        tree = KDTree(original_vertices)\n","\n","        # Find nearest neighbors for each stego vertex\n","        distances, indices = tree.query(stego_vertices)\n","\n","        # Create aligned vertex arrays\n","        aligned_original = original_vertices[indices]\n","        aligned_stego = stego_vertices\n","\n","        return aligned_original, aligned_stego, distances\n","\n","    def load_models(self, original_path, stego_path, align=True):\n","        \"\"\"Load and preprocess original and stego 3D models\"\"\"\n","        try:\n","            # Load meshes\n","            original_mesh = trimesh.load(original_path)\n","            stego_mesh = trimesh.load(stego_path)\n","\n","            # Check if loaded data is a Scene and extract the first mesh if it is\n","            if isinstance(original_mesh, trimesh.Scene):\n","                original_mesh = next(iter(original_mesh.geometry.values())) # Get the first mesh from the scene\n","            if isinstance(stego_mesh, trimesh.Scene):\n","                stego_mesh = next(iter(stego_mesh.geometry.values())) # Get the first mesh from the scene\n","\n","            print(f\"Original vertices: {len(original_mesh.vertices)}\")\n","            print(f\"Stego vertices: {len(stego_mesh.vertices)}\")\n","\n","            # Preprocess meshes\n","            original_mesh, stego_mesh = self.preprocess_models(original_mesh, stego_mesh)\n","\n","            if align:\n","                # Align vertices\n","                self.original_vertices, self.stego_vertices, distances = self.align_vertices(\n","                    original_mesh.vertices,\n","                    stego_mesh.vertices\n","                )\n","\n","                # Print alignment statistics\n","                print(f\"\\nAlignment Statistics:\")\n","                print(f\"Mean distance: {np.mean(distances):.6f}\")\n","                print(f\"Max distance: {np.max(distances):.6f}\")\n","                print(f\"Aligned vertices: {len(self.original_vertices)}\")\n","            else:\n","                if len(original_mesh.vertices) != len(stego_mesh.vertices):\n","                    raise ValueError(\"Models have different number of vertices and alignment is disabled\")\n","                self.original_vertices = original_mesh.vertices\n","                self.stego_vertices = stego_mesh.vertices\n","\n","            self.original_mesh = original_mesh\n","            self.stego_mesh = stego_mesh\n","\n","            return True\n","\n","        except Exception as e:\n","            print(f\"Error loading models: {str(e)}\")\n","            return False\n","\n","    def calculate_vertex_error_map(self):\n","        \"\"\"Calculate and visualize vertex-wise errors\"\"\"\n","        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n","        return errors\n","\n","\n","\n","    def calculate_psnr(self):\n","        \"\"\"Calculate Peak Signal-to-Noise Ratio\"\"\"\n","        mse = np.mean((self.original_vertices - self.stego_vertices) ** 2)\n","        if mse == 0:\n","            return float('inf')\n","\n","        max_val = np.max(self.original_vertices) - np.min(self.original_vertices)\n","        psnr = 20 * math.log10(max_val / math.sqrt(mse))\n","        self.metrics['PSNR'] = psnr\n","        return psnr\n","\n","    def calculate_ssim(self):\n","        \"\"\"Calculate Structural Similarity Index\"\"\"\n","        orig_reshaped = self.original_vertices.reshape(-1, 3)\n","        stego_reshaped = self.stego_vertices.reshape(-1, 3)\n","\n","        ssim_scores = []\n","        for i in range(3):\n","            score = structural_similarity(\n","                orig_reshaped[:, i],\n","                stego_reshaped[:, i],\n","                data_range=np.max(orig_reshaped[:, i]) - np.min(orig_reshaped[:, i])\n","            )\n","            ssim_scores.append(score)\n","\n","        ssim = np.mean(ssim_scores)\n","        self.metrics['SSIM'] = ssim\n","        return ssim\n","\n","    def calculate_mse(self):\n","        \"\"\"Calculate Mean Squared Error\"\"\"\n","        mse = mean_squared_error(self.original_vertices, self.stego_vertices)\n","        self.metrics['MSE'] = mse\n","        return mse\n","\n","    def calculate_rmse(self):\n","        \"\"\"Calculate Root Mean Squared Error\"\"\"\n","        rmse = np.sqrt(self.calculate_mse())\n","        self.metrics['RMSE'] = rmse\n","        return rmse\n","\n","    def calculate_ber(self, threshold=1e-6):\n","        \"\"\"Calculate Bit Error Rate\"\"\"\n","        differences = np.abs(self.original_vertices - self.stego_vertices)\n","        binary_orig = (self.original_vertices > threshold).astype(int)\n","        binary_stego = (self.stego_vertices > threshold).astype(int)\n","\n","        total_bits = np.prod(binary_orig.shape)\n","        error_bits = np.sum(binary_orig != binary_stego)\n","\n","        ber = error_bits / total_bits\n","        self.metrics['BER'] = ber\n","        return ber\n","\n","    def calculate_hausdorff_distance(self):\n","        \"\"\"Calculate Hausdorff distance between original and stego models\"\"\"\n","        def directed_hausdorff(source, target):\n","            tree = KDTree(target)\n","            distances, _ = tree.query(source)\n","            return np.max(distances)\n","\n","        forward = directed_hausdorff(self.original_vertices, self.stego_vertices)\n","        backward = directed_hausdorff(self.stego_vertices, self.original_vertices)\n","\n","        hausdorff = max(forward, backward)\n","        self.metrics['Hausdorff'] = hausdorff\n","        return hausdorff\n","\n","    def calculate_histogram_similarity(self, bins=50):\n","        \"\"\"Calculate histogram similarity using Wasserstein distance\"\"\"\n","        distances = []\n","\n","        for i in range(3):\n","            hist_orig, _ = np.histogram(self.original_vertices[:, i], bins=bins, density=True)\n","            hist_stego, _ = np.histogram(self.stego_vertices[:, i], bins=bins, density=True)\n","\n","            distance = wasserstein_distance(hist_orig, hist_stego)\n","            distances.append(distance)\n","\n","        hist_similarity = 1 / (1 + np.mean(distances))\n","        self.metrics['Histogram_Similarity'] = hist_similarity\n","        return hist_similarity\n","\n","    def plot_histograms(self, save_path=None):\n","        \"\"\"Plot histograms of original and stego models\"\"\"\n","        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","        coords = ['X', 'Y', 'Z']\n","\n","        for i, (ax, coord) in enumerate(zip(axes, coords)):\n","            ax.hist(self.original_vertices[:, i], bins=50, alpha=0.5, label='Original', density=True)\n","            ax.hist(self.stego_vertices[:, i], bins=50, alpha=0.5, label='Stego', density=True)\n","            ax.set_title(f'{coord} Coordinate Distribution')\n","            ax.set_xlabel(f'{coord} Value')\n","            ax.set_ylabel('Density')\n","            ax.legend()\n","\n","        plt.tight_layout()\n","        if save_path:\n","            plt.savefig(save_path)\n","            plt.close()\n","        else:\n","            plt.show()\n","\n","    def plot_error_distribution(self, save_path=None):\n","        \"\"\"Plot the distribution of geometric errors\"\"\"\n","        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n","\n","        plt.figure(figsize=(10, 6))\n","        plt.hist(errors, bins=50, density=True)\n","        plt.title('Geometric Error Distribution')\n","        plt.xlabel('Error Magnitude')\n","        plt.ylabel('Density')\n","\n","        if save_path:\n","            plt.savefig(save_path)\n","            plt.close()\n","        else:\n","            plt.show()\n","\n","    def evaluate_all(self, plot=True, save_plots=False):\n","        \"\"\"Calculate all metrics and optionally generate plots\"\"\"\n","        metrics = {\n","            'PSNR': self.calculate_psnr(),\n","            'SSIM': self.calculate_ssim(),\n","            'MSE': self.calculate_mse(),\n","            'RMSE': self.calculate_rmse(),\n","            'BER': self.calculate_ber(),\n","            'Hausdorff': self.calculate_hausdorff_distance(),\n","            'Histogram_Similarity': self.calculate_histogram_similarity()\n","        }\n","\n","        if plot:\n","            self.plot_histograms(save_path='/content/drive/MyDrive/OutputPaper2/histograms_15742_Zombie_Arm_v1_.png' if save_plots else None)\n","            self.plot_error_distribution(save_path='/content/drive/MyDrive/OutputPaper2/error_distribution_15742_Zombie_Arm_v1.png' if save_plots else None)\n","            #self.visualize_error_map(save_path='error_map.png' if save_plots else None)\n","\n","        return metrics\n","    def generate_report(self, output_path='/content/drive/MyDrive/OutputPaper2/evaluation_report_15742_Zombie_Arm_v1.txt'):\n","        \"\"\"Generate a detailed evaluation report\"\"\"\n","        with open(output_path, 'w') as f:\n","            f.write(\"3D Steganography Evaluation Report\\n\")\n","            f.write(\"=================================\\n\\n\")\n","\n","            # Model information\n","            f.write(\"Model Information:\\n\")\n","            f.write(f\"Number of vertices: {len(self.original_vertices)}\\n\")\n","            f.write(f\"Number of faces: {len(self.original_mesh.faces)}\\n\\n\")\n","\n","            # Metrics\n","            f.write(\"Quality Metrics:\\n\")\n","            for metric, value in self.metrics.items():\n","                f.write(f\"{metric}: {value:.6f}\\n\")\n","\n","            f.write(\"\\nInterpretation:\\n\")\n","            f.write(\"- PSNR > 30 dB typically indicates good quality\\n\")\n","            f.write(\"- SSIM closer to 1 indicates better structural preservation\\n\")\n","            f.write(\"- Lower MSE and RMSE values indicate better similarity\\n\")\n","            f.write(\"- Lower BER indicates better steganographic accuracy\\n\")\n","            f.write(\"- Histogram similarity closer to 1 indicates better statistical imperceptibility\\n\")\n","\n","def main():\n","    # Initialize evaluator\n","    evaluator = Stego3DEvaluator()\n","\n","    # Load and align models\n","    if not evaluator.load_models('/content/drive/MyDrive/OutputPaper2/modified_15742_Zombie_Arm_v1.obj', '/content/drive/MyDrive/OutputPaper2/15742_Zombie_Arm_v1.obj', align=True):\n","        return\n","\n","    # Perform evaluation\n","    metrics = evaluator.evaluate_all(plot=True, save_plots=True)\n","\n","    # Print results\n","    print(\"\\nEvaluation Results:\")\n","    for metric, value in metrics.items():\n","        print(f\"{metric}: {value:.6f}\")\n","    evaluator.generate_report()\n","    print(\"\\nDetailed report saved to '/content/drive/MyDrive/OutputPaper2/evaluation_report_15742_Zombie_Arm_v1.txt'\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736793178369,"user_tz":-300,"elapsed":3551,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"outputId":"e1dc339d-f049-4f68-f966-35c11584ada2","id":"_InP3_P_74MP"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Original vertices: 37385\n","Stego vertices: 37472\n","\n","Alignment Statistics:\n","Mean distance: 0.002288\n","Max distance: 0.003917\n","Aligned vertices: 37472\n","\n","Evaluation Results:\n","PSNR: 61.106745\n","SSIM: 0.999591\n","MSE: 0.000002\n","RMSE: 0.001428\n","BER: 0.000845\n","Hausdorff: 0.003917\n","Histogram_Similarity: 0.992270\n","\n","Detailed report saved to '/content/drive/MyDrive/OutputPaper2/evaluation_report_15742_Zombie_Arm_v1.txt'\n"]}]},{"cell_type":"markdown","source":["Evaluation for 16794_Harpy_V1"],"metadata":{"id":"Kaz58JFB95xr"}},{"cell_type":"code","source":[],"metadata":{"id":"blXjTPfS98aL"},"execution_count":null,"outputs":[]},{"source":["#!pip install pyglet\n","#!pip install pyglet<2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import mean_squared_error\n","import trimesh\n","from scipy.stats import wasserstein_distance\n","from skimage.metrics import structural_similarity\n","import math\n","from scipy.spatial import KDTree\n","import os\n","\n","class Stego3DEvaluator:\n","    def __init__(self):\n","        \"\"\"Initialize the 3D steganography evaluator\"\"\"\n","        self.metrics = {}\n","\n","    def preprocess_models(self, original_mesh, stego_mesh):\n","        \"\"\"Preprocess and align models to ensure compatibility\"\"\"\n","        # Center both meshes\n","        original_mesh.vertices -= original_mesh.vertices.mean(axis=0)\n","        stego_mesh.vertices -= stego_mesh.vertices.mean(axis=0)\n","\n","        # Scale to unit cube\n","        original_scale = np.max(np.abs(original_mesh.vertices))\n","        stego_scale = np.max(np.abs(stego_mesh.vertices))\n","\n","        original_mesh.vertices /= original_scale\n","        stego_mesh.vertices /= stego_scale\n","\n","        return original_mesh, stego_mesh\n","\n","    def align_vertices(self, original_vertices, stego_vertices):\n","        \"\"\"Align vertices between models using nearest neighbor matching\"\"\"\n","        # Build KD-tree for faster nearest neighbor search\n","        tree = KDTree(original_vertices)\n","\n","        # Find nearest neighbors for each stego vertex\n","        distances, indices = tree.query(stego_vertices)\n","\n","        # Create aligned vertex arrays\n","        aligned_original = original_vertices[indices]\n","        aligned_stego = stego_vertices\n","\n","        return aligned_original, aligned_stego, distances\n","\n","    def load_models(self, original_path, stego_path, align=True):\n","        \"\"\"Load and preprocess original and stego 3D models\"\"\"\n","        try:\n","            # Load meshes\n","            original_mesh = trimesh.load(original_path)\n","            stego_mesh = trimesh.load(stego_path)\n","\n","            # Check if loaded data is a Scene and extract the first mesh if it is\n","            if isinstance(original_mesh, trimesh.Scene):\n","                original_mesh = next(iter(original_mesh.geometry.values())) # Get the first mesh from the scene\n","            if isinstance(stego_mesh, trimesh.Scene):\n","                stego_mesh = next(iter(stego_mesh.geometry.values())) # Get the first mesh from the scene\n","\n","            print(f\"Original vertices: {len(original_mesh.vertices)}\")\n","            print(f\"Stego vertices: {len(stego_mesh.vertices)}\")\n","\n","            # Preprocess meshes\n","            original_mesh, stego_mesh = self.preprocess_models(original_mesh, stego_mesh)\n","\n","            if align:\n","                # Align vertices\n","                self.original_vertices, self.stego_vertices, distances = self.align_vertices(\n","                    original_mesh.vertices,\n","                    stego_mesh.vertices\n","                )\n","\n","                # Print alignment statistics\n","                print(f\"\\nAlignment Statistics:\")\n","                print(f\"Mean distance: {np.mean(distances):.6f}\")\n","                print(f\"Max distance: {np.max(distances):.6f}\")\n","                print(f\"Aligned vertices: {len(self.original_vertices)}\")\n","            else:\n","                if len(original_mesh.vertices) != len(stego_mesh.vertices):\n","                    raise ValueError(\"Models have different number of vertices and alignment is disabled\")\n","                self.original_vertices = original_mesh.vertices\n","                self.stego_vertices = stego_mesh.vertices\n","\n","            self.original_mesh = original_mesh\n","            self.stego_mesh = stego_mesh\n","\n","            return True\n","\n","        except Exception as e:\n","            print(f\"Error loading models: {str(e)}\")\n","            return False\n","\n","    def calculate_vertex_error_map(self):\n","        \"\"\"Calculate and visualize vertex-wise errors\"\"\"\n","        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n","        return errors\n","\n","\n","\n","    def calculate_psnr(self):\n","        \"\"\"Calculate Peak Signal-to-Noise Ratio\"\"\"\n","        mse = np.mean((self.original_vertices - self.stego_vertices) ** 2)\n","        if mse == 0:\n","            return float('inf')\n","\n","        max_val = np.max(self.original_vertices) - np.min(self.original_vertices)\n","        psnr = 20 * math.log10(max_val / math.sqrt(mse))\n","        self.metrics['PSNR'] = psnr\n","        return psnr\n","\n","    def calculate_ssim(self):\n","        \"\"\"Calculate Structural Similarity Index\"\"\"\n","        orig_reshaped = self.original_vertices.reshape(-1, 3)\n","        stego_reshaped = self.stego_vertices.reshape(-1, 3)\n","\n","        ssim_scores = []\n","        for i in range(3):\n","            score = structural_similarity(\n","                orig_reshaped[:, i],\n","                stego_reshaped[:, i],\n","                data_range=np.max(orig_reshaped[:, i]) - np.min(orig_reshaped[:, i])\n","            )\n","            ssim_scores.append(score)\n","\n","        ssim = np.mean(ssim_scores)\n","        self.metrics['SSIM'] = ssim\n","        return ssim\n","\n","    def calculate_mse(self):\n","        \"\"\"Calculate Mean Squared Error\"\"\"\n","        mse = mean_squared_error(self.original_vertices, self.stego_vertices)\n","        self.metrics['MSE'] = mse\n","        return mse\n","\n","    def calculate_rmse(self):\n","        \"\"\"Calculate Root Mean Squared Error\"\"\"\n","        rmse = np.sqrt(self.calculate_mse())\n","        self.metrics['RMSE'] = rmse\n","        return rmse\n","\n","    def calculate_ber(self, threshold=1e-6):\n","        \"\"\"Calculate Bit Error Rate\"\"\"\n","        differences = np.abs(self.original_vertices - self.stego_vertices)\n","        binary_orig = (self.original_vertices > threshold).astype(int)\n","        binary_stego = (self.stego_vertices > threshold).astype(int)\n","\n","        total_bits = np.prod(binary_orig.shape)\n","        error_bits = np.sum(binary_orig != binary_stego)\n","\n","        ber = error_bits / total_bits\n","        self.metrics['BER'] = ber\n","        return ber\n","\n","    def calculate_hausdorff_distance(self):\n","        \"\"\"Calculate Hausdorff distance between original and stego models\"\"\"\n","        def directed_hausdorff(source, target):\n","            tree = KDTree(target)\n","            distances, _ = tree.query(source)\n","            return np.max(distances)\n","\n","        forward = directed_hausdorff(self.original_vertices, self.stego_vertices)\n","        backward = directed_hausdorff(self.stego_vertices, self.original_vertices)\n","\n","        hausdorff = max(forward, backward)\n","        self.metrics['Hausdorff'] = hausdorff\n","        return hausdorff\n","\n","    def calculate_histogram_similarity(self, bins=50):\n","        \"\"\"Calculate histogram similarity using Wasserstein distance\"\"\"\n","        distances = []\n","\n","        for i in range(3):\n","            hist_orig, _ = np.histogram(self.original_vertices[:, i], bins=bins, density=True)\n","            hist_stego, _ = np.histogram(self.stego_vertices[:, i], bins=bins, density=True)\n","\n","            distance = wasserstein_distance(hist_orig, hist_stego)\n","            distances.append(distance)\n","\n","        hist_similarity = 1 / (1 + np.mean(distances))\n","        self.metrics['Histogram_Similarity'] = hist_similarity\n","        return hist_similarity\n","\n","    def plot_histograms(self, save_path=None):\n","        \"\"\"Plot histograms of original and stego models\"\"\"\n","        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","        coords = ['X', 'Y', 'Z']\n","\n","        for i, (ax, coord) in enumerate(zip(axes, coords)):\n","            ax.hist(self.original_vertices[:, i], bins=50, alpha=0.5, label='Original', density=True)\n","            ax.hist(self.stego_vertices[:, i], bins=50, alpha=0.5, label='Stego', density=True)\n","            ax.set_title(f'{coord} Coordinate Distribution')\n","            ax.set_xlabel(f'{coord} Value')\n","            ax.set_ylabel('Density')\n","            ax.legend()\n","\n","        plt.tight_layout()\n","        if save_path:\n","            plt.savefig(save_path)\n","            plt.close()\n","        else:\n","            plt.show()\n","\n","    def plot_error_distribution(self, save_path=None):\n","        \"\"\"Plot the distribution of geometric errors\"\"\"\n","        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n","\n","        plt.figure(figsize=(10, 6))\n","        plt.hist(errors, bins=50, density=True)\n","        plt.title('Geometric Error Distribution')\n","        plt.xlabel('Error Magnitude')\n","        plt.ylabel('Density')\n","\n","        if save_path:\n","            plt.savefig(save_path)\n","            plt.close()\n","        else:\n","            plt.show()\n","\n","    def evaluate_all(self, plot=True, save_plots=False):\n","        \"\"\"Calculate all metrics and optionally generate plots\"\"\"\n","        metrics = {\n","            'PSNR': self.calculate_psnr(),\n","            'SSIM': self.calculate_ssim(),\n","            'MSE': self.calculate_mse(),\n","            'RMSE': self.calculate_rmse(),\n","            'BER': self.calculate_ber(),\n","            'Hausdorff': self.calculate_hausdorff_distance(),\n","            'Histogram_Similarity': self.calculate_histogram_similarity()\n","        }\n","\n","        if plot:\n","            self.plot_histograms(save_path='/content/drive/MyDrive/OutputPaper2/histograms_16794_Harpy_V1_.png' if save_plots else None)\n","            self.plot_error_distribution(save_path='/content/drive/MyDrive/OutputPaper2/error_distribution_16794_Harpy_V1.png' if save_plots else None)\n","            #self.visualize_error_map(save_path='error_map.png' if save_plots else None)\n","\n","        return metrics\n","    def generate_report(self, output_path='/content/drive/MyDrive/OutputPaper2/evaluation_report_16794_Harpy_V1.txt'):\n","        \"\"\"Generate a detailed evaluation report\"\"\"\n","        with open(output_path, 'w') as f:\n","            f.write(\"3D Steganography Evaluation Report\\n\")\n","            f.write(\"=================================\\n\\n\")\n","\n","            # Model information\n","            f.write(\"Model Information:\\n\")\n","            f.write(f\"Number of vertices: {len(self.original_vertices)}\\n\")\n","            f.write(f\"Number of faces: {len(self.original_mesh.faces)}\\n\\n\")\n","\n","            # Metrics\n","            f.write(\"Quality Metrics:\\n\")\n","            for metric, value in self.metrics.items():\n","                f.write(f\"{metric}: {value:.6f}\\n\")\n","\n","            f.write(\"\\nInterpretation:\\n\")\n","            f.write(\"- PSNR > 30 dB typically indicates good quality\\n\")\n","            f.write(\"- SSIM closer to 1 indicates better structural preservation\\n\")\n","            f.write(\"- Lower MSE and RMSE values indicate better similarity\\n\")\n","            f.write(\"- Lower BER indicates better steganographic accuracy\\n\")\n","            f.write(\"- Histogram similarity closer to 1 indicates better statistical imperceptibility\\n\")\n","\n","def main():\n","    # Initialize evaluator\n","    evaluator = Stego3DEvaluator()\n","\n","    # Load and align models\n","    if not evaluator.load_models('/content/drive/MyDrive/OutputPaper2/modified_16794_Harpy_V1.obj', '/content/drive/MyDrive/OutputPaper2/16794_Harpy_V1.obj', align=True):\n","        return\n","\n","    # Perform evaluation\n","    metrics = evaluator.evaluate_all(plot=True, save_plots=True)\n","\n","    # Print results\n","    print(\"\\nEvaluation Results:\")\n","    for metric, value in metrics.items():\n","        print(f\"{metric}: {value:.6f}\")\n","    evaluator.generate_report()\n","    print(\"\\nDetailed report saved to '/content/drive/MyDrive/OutputPaper2/evaluation_report_16794_Harpy_V1.txt'\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736793706013,"user_tz":-300,"elapsed":3854,"user":{"displayName":"Muhammad Sajid","userId":"14699062591292427201"}},"outputId":"6436b5c1-2ffb-4ae4-b2db-2d9174b15040","id":"BK92PVf7-ATL"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Original vertices: 65981\n","Stego vertices: 66143\n","\n","Alignment Statistics:\n","Mean distance: 0.001147\n","Max distance: 0.001282\n","Aligned vertices: 66143\n","\n","Evaluation Results:\n","PSNR: 69.562818\n","SSIM: 0.999897\n","MSE: 0.000000\n","RMSE: 0.000665\n","BER: 0.000297\n","Hausdorff: 0.001282\n","Histogram_Similarity: 0.998757\n","\n","Detailed report saved to '/content/drive/MyDrive/OutputPaper2/evaluation_report_16794_Harpy_V1.txt'\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1Xw-Jgx8Trb63QWvvGTRX2t0_CWQpcXAO","timestamp":1736790312693},{"file_id":"1grVxVZCJ9RIkKNTvgg8WqSlOy8je7C9h","timestamp":1736780024033}],"mount_file_id":"1NR7NroBVWYQqLbFtz607w-2W-APH_Gyi","authorship_tag":"ABX9TyMom/wy+uJtU5y4HHKXZWz6"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}