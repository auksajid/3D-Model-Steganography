{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgRS7IvE7e2n",
        "outputId": "979fb2a4-63de-469c-df6b-b7e49a266221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic face model generated: /content/drive/MyDrive/OutputPaper2/face_model.obj\n",
            "Textured face model generated:\n",
            "OBJ file: /content/drive/MyDrive/OutputPaper2/face_model.obj\n",
            "MTL file: /content/drive/MyDrive/OutputPaper2/face_model.mtl\n",
            "Texture file: /content/drive/MyDrive/OutputPaper2/face_model_texture.png\n"
          ]
        }
      ],
      "source": [
        "#!pip install mediapipe\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "\n",
        "class FaceModelGenerator:\n",
        "    def __init__(self):\n",
        "        self.mp_face_mesh = mp.solutions.face_mesh\n",
        "        self.face_mesh = self.mp_face_mesh.FaceMesh(\n",
        "            static_image_mode=True,\n",
        "            max_num_faces=1,\n",
        "            min_detection_confidence=0.5\n",
        "        )\n",
        "        # Load the face mesh tesselation\n",
        "        self.mp_face_mesh_tesselation = mp.solutions.face_mesh_connections\n",
        "\n",
        "\n",
        "    def generate_obj_from_image(self, image_path, output_path='/content/drive/MyDrive/OutputPaper2/face_model.obj'):\n",
        "        \"\"\"Generate a 3D face model OBJ file from an image\"\"\"\n",
        "        # Read image\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(\"Could not read image file\")\n",
        "\n",
        "        # Convert to RGB for MediaPipe\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Detect face landmarks\n",
        "        results = self.face_mesh.process(image_rgb)\n",
        "\n",
        "        if not results.multi_face_landmarks:\n",
        "            raise ValueError(\"No face detected in image\")\n",
        "\n",
        "        # Get face landmarks\n",
        "        face_landmarks = results.multi_face_landmarks[0]\n",
        "\n",
        "        # Convert landmarks to 3D points\n",
        "        vertices = []\n",
        "        for landmark in face_landmarks.landmark:\n",
        "            vertices.append([\n",
        "                landmark.x * image.shape[1],\n",
        "                -landmark.y * image.shape[0],  # Flip Y for standard 3D coordinate system\n",
        "                landmark.z * image.shape[1]  # Scale Z similarly to X\n",
        "            ])\n",
        "        vertices = np.array(vertices)\n",
        "\n",
        "        # Define faces using MediaPipe's face mesh tesselation\n",
        "        # Get the connections from FACEMESH_TESSELATION\n",
        "        connections = self.mp_face_mesh_tesselation.FACEMESH_TESSELATION\n",
        "         # Extract the faces (triangles) from the connections\n",
        "        faces = []\n",
        "        for connection in connections:\n",
        "            # Assuming each connection represents an edge of a triangle\n",
        "            # We need to find the third vertex to form the triangle\n",
        "            # This is a simplification and might not be completely accurate\n",
        "            # You might need to adjust this logic based on the actual data in FACEMESH_TESSELATION\n",
        "            v1, v2 = connection\n",
        "            # Find a third vertex connected to both v1 and v2 (this is a heuristic)\n",
        "            for other_connection in connections:\n",
        "                if v1 in other_connection and v2 not in other_connection:\n",
        "                    v3 = other_connection[0] if other_connection[1] == v1 else other_connection[1]\n",
        "                    faces.append([v1, v2, v3])\n",
        "                    break\n",
        "                elif v2 in other_connection and v1 not in other_connection:\n",
        "                    v3 = other_connection[0] if other_connection[1] == v2 else other_connection[1]\n",
        "                    faces.append([v1, v2, v3])\n",
        "                    break\n",
        "\n",
        "        # Write OBJ file\n",
        "        with open(output_path, 'w') as f:\n",
        "            # Write vertices\n",
        "            for vertex in vertices:\n",
        "                f.write(f'v {vertex[0]:.6f} {vertex[1]:.6f} {vertex[2]:.6f}\\n')\n",
        "\n",
        "            # Write faces (OBJ uses 1-based indexing)\n",
        "            for face in faces:\n",
        "                f.write(f'f {face[0]+1} {face[1]+1} {face[2]+1}\\n')\n",
        "\n",
        "        return output_path\n",
        "\n",
        "    def generate_with_texture(self, image_path, output_base_path='/content/drive/MyDrive/OutputPaper2/face_model'):\n",
        "        \"\"\"Generate a textured 3D face model with materials\"\"\"\n",
        "        # Read and process image as before\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(\"Could not read image file\")\n",
        "\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        results = self.face_mesh.process(image_rgb)\n",
        "\n",
        "        if not results.multi_face_landmarks:\n",
        "            raise ValueError(\"No face detected in image\")\n",
        "\n",
        "        # Generate UV coordinates\n",
        "        face_landmarks = results.multi_face_landmarks[0]\n",
        "        vertices = []\n",
        "        uv_coords = []\n",
        "\n",
        "        for landmark in face_landmarks.landmark:\n",
        "            vertices.append([\n",
        "                landmark.x * image.shape[1],\n",
        "                -landmark.y * image.shape[0],\n",
        "                landmark.z * image.shape[1]\n",
        "            ])\n",
        "            # Generate UV coordinates (simple mapping)\n",
        "            uv_coords.append([landmark.x, landmark.y])\n",
        "\n",
        "        vertices = np.array(vertices)\n",
        "       # Access face mesh tesselation\n",
        "        # Get the connections from FACEMESH_TESSELATION\n",
        "        connections = self.mp_face_mesh_tesselation.FACEMESH_TESSELATION\n",
        "\n",
        "        # Extract the faces (triangles) from the connections\n",
        "        faces = []\n",
        "        for connection in connections:\n",
        "            # Assuming each connection represents an edge of a triangle\n",
        "            # We need to find the third vertex to form the triangle\n",
        "            # This is a simplification and might not be completely accurate\n",
        "            # You might need to adjust this logic based on the actual data in FACEMESH_TESSELATION\n",
        "            v1, v2 = connection\n",
        "            # Find a third vertex connected to both v1 and v2 (this is a heuristic)\n",
        "            for other_connection in connections:\n",
        "                if v1 in other_connection and v2 not in other_connection:\n",
        "                    v3 = other_connection[0] if other_connection[1] == v1 else other_connection[1]\n",
        "                    faces.append([v1, v2, v3])\n",
        "                    break\n",
        "                elif v2 in other_connection and v1 not in other_connection:\n",
        "                    v3 = other_connection[0] if other_connection[1] == v2 else other_connection[1]\n",
        "                    faces.append([v1, v2, v3])\n",
        "                    break\n",
        "\n",
        "        # Write OBJ with texture coordinates\n",
        "        obj_path = f'{output_base_path}.obj'\n",
        "        mtl_path = f'{output_base_path}.mtl'\n",
        "        texture_path = f'{output_base_path}_texture.png'\n",
        "\n",
        "        # Save texture image\n",
        "        cv2.imwrite(texture_path, image)\n",
        "\n",
        "        # Write MTL file\n",
        "        with open(mtl_path, 'w') as f:\n",
        "            f.write('newmtl material0\\n')\n",
        "            f.write('Ka 1.000000 1.000000 1.000000\\n')\n",
        "            f.write('Kd 1.000000 1.000000 1.000000\\n')\n",
        "            f.write('Ks 0.000000 0.000000 0.000000\\n')\n",
        "            f.write(f'map_Kd {output_base_path}_texture.png\\n')\n",
        "\n",
        "        # Write OBJ file\n",
        "        with open(obj_path, 'w') as f:\n",
        "            f.write(f'mtllib {output_base_path}.mtl\\n')\n",
        "\n",
        "            # Write vertices\n",
        "            for vertex in vertices:\n",
        "                f.write(f'v {vertex[0]:.6f} {vertex[1]:.6f} {vertex[2]:.6f}\\n')\n",
        "\n",
        "            # Write texture coordinates\n",
        "            for uv in uv_coords:\n",
        "                f.write(f'vt {uv[0]:.6f} {uv[1]:.6f}\\n')\n",
        "\n",
        "            # Write faces with texture coordinates\n",
        "            f.write('usemtl material0\\n')\n",
        "            for face in faces:\n",
        "                # OBJ uses 1-based indexing\n",
        "                f.write(f'f {face[0]+1}/{face[0]+1} {face[1]+1}/{face[1]+1} {face[2]+1}/{face[2]+1}\\n')\n",
        "\n",
        "        return obj_path, mtl_path, texture_path\n",
        "\n",
        "def main():\n",
        "    # Initialize generator\n",
        "    generator = FaceModelGenerator()\n",
        "\n",
        "    # Generate basic model\n",
        "    try:\n",
        "        obj_path = generator.generate_obj_from_image('/content/drive/MyDrive/InputPaper2/FaceModel.png')\n",
        "        print(f\"Basic face model generated: {obj_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating basic model: {str(e)}\")\n",
        "\n",
        "    # Generate textured model\n",
        "    try:\n",
        "        obj_path, mtl_path, texture_path = generator.generate_with_texture('/content/drive/MyDrive/InputPaper2/FaceModel.png')\n",
        "        print(f\"Textured face model generated:\")\n",
        "        print(f\"OBJ file: {obj_path}\")\n",
        "        print(f\"MTL file: {mtl_path}\")\n",
        "        print(f\"Texture file: {texture_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating textured model: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgfQzI6PLc4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98bbb9c9-5056-4909-cd22-1be266c9ffb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycryptodome\n",
            "Successfully installed pycryptodome-3.21.0\n",
            "Collecting trimesh\n",
            "  Downloading trimesh-4.5.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from trimesh) (1.26.4)\n",
            "Downloading trimesh-4.5.3-py3-none-any.whl (704 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.8/704.8 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trimesh\n",
            "Successfully installed trimesh-4.5.3\n"
          ]
        }
      ],
      "source": [
        "#!pip install pycryptodome\n",
        "#!pip install trimesh\n",
        "import numpy as np\n",
        "from Crypto.Cipher import AES\n",
        "from Crypto.Util.Padding import pad, unpad\n",
        "import hashlib\n",
        "import secrets\n",
        "import struct\n",
        "import trimesh\n",
        "import scipy.spatial as spatial\n",
        "\n",
        "class SecureFaceSteganography:\n",
        "    def __init__(self):\n",
        "        # ... (other code)\n",
        "        self.LANDMARK_REGIONS = {\n",
        "            'forehead': [(0.2, 0.8, 0.5), (0.8, 0.8, 0.5)],  # Wider bounding box\n",
        "            'cheeks': [(0.1, 0.5, 0.5), (0.9, 0.5, 0.5)],  # Wider bounding box\n",
        "            'jaw': [(0.2, 0.2, 0.5), (0.8, 0.2, 0.5)],  # Wider bounding box\n",
        "            'nose': [(0.4, 0.6, 0.5), (0.6, 0.6, 0.5)],  # Added nose region\n",
        "            'chin': [(0.5, 0.1, 0.5)]  #chin region\n",
        "        }\n",
        "        # Define SALT_SIZE and BLOCK_SIZE in the __init__ method\n",
        "        self.SALT_SIZE = 16  # 128 bits for salt\n",
        "        self.BLOCK_SIZE = 16 # 128 bits for block size\n",
        "\n",
        "    def load_face_model(self, file_path):\n",
        "        \"\"\"Load 3D face model and prepare it for steganography\"\"\"\n",
        "        try:\n",
        "            mesh = trimesh.load(file_path)\n",
        "            return {\n",
        "                'vertices': np.array(mesh.vertices),\n",
        "                'faces': np.array(mesh.faces),\n",
        "                'normals': np.array(mesh.vertex_normals)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error loading face model: {str(e)}\")\n",
        "\n",
        "    def identify_landmark_vertices(self, vertices, landmark_regions=None):\n",
        "        \"\"\"Identify vertices near facial landmarks for data embedding\"\"\"\n",
        "        if landmark_regions is None:\n",
        "            landmark_regions = self.LANDMARK_REGIONS\n",
        "\n",
        "        landmark_vertices = []\n",
        "        kdtree = spatial.KDTree(vertices)\n",
        "        for region, points in landmark_regions.items():\n",
        "            for point in points:\n",
        "                # Find nearest vertices to landmark points\n",
        "                # Increased k to 100 (or even higher if needed) to find more neighboring vertices\n",
        "                distances, indices = kdtree.query(point, k=1000)  # Increased k here\n",
        "                landmark_vertices.extend(indices)\n",
        "        return sorted(set(landmark_vertices))  # Remove duplicates\n",
        "\n",
        "    def compute_vertex_importance(self, vertices, faces, normals):\n",
        "        \"\"\"Compute vertex importance based on geometric features\"\"\"\n",
        "        importance = np.zeros(len(vertices))\n",
        "\n",
        "        # Calculate curvature (simplified)\n",
        "        for i, vertex in enumerate(vertices):\n",
        "            # Find connected vertices\n",
        "            connected = faces[np.any(faces == i, axis=1)]\n",
        "            connected = np.unique(connected.flatten())\n",
        "            connected = connected[connected != i]\n",
        "\n",
        "            # Calculate local curvature\n",
        "            if len(connected) > 0:\n",
        "                connected_vertices = vertices[connected]\n",
        "                mean_position = np.mean(connected_vertices, axis=0)\n",
        "                displacement = np.linalg.norm(vertex - mean_position)\n",
        "                importance[i] = displacement\n",
        "\n",
        "        return importance\n",
        "\n",
        "    def generate_passphrase(self, length=32):\n",
        "        \"\"\"Generate a cryptographically secure random passphrase\"\"\"\n",
        "        charset = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&*\"\n",
        "        return ''.join(secrets.choice(charset) for _ in range(length))\n",
        "\n",
        "    def derive_key(self, passphrase, salt):\n",
        "        \"\"\"Derive encryption key using SHA-256 with salt\"\"\"\n",
        "        key_material = hashlib.sha256()\n",
        "        key_material.update(passphrase.encode('utf-8'))\n",
        "        key_material.update(salt)\n",
        "        return key_material.digest()\n",
        "\n",
        "    def encrypt_message(self, message, passphrase):\n",
        "        \"\"\"Encrypt a message using AES-128-CBC with secure key derivation\"\"\"\n",
        "        salt = secrets.token_bytes(self.SALT_SIZE)\n",
        "        key = self.derive_key(passphrase, salt)\n",
        "        iv = secrets.token_bytes(self.BLOCK_SIZE)\n",
        "\n",
        "        cipher = AES.new(key, AES.MODE_CBC, iv)\n",
        "        padded_data = pad(message.encode('utf-8'), self.BLOCK_SIZE)\n",
        "        ciphertext = cipher.encrypt(padded_data)\n",
        "\n",
        "        return salt + iv + ciphertext\n",
        "\n",
        "    def decrypt_message(self, encrypted_data, passphrase):\n",
        "        \"\"\"Decrypt a message using AES-128-CBC\"\"\"\n",
        "        salt = encrypted_data[:self.SALT_SIZE]\n",
        "        iv = encrypted_data[self.SALT_SIZE:self.SALT_SIZE + self.BLOCK_SIZE]\n",
        "        ciphertext = encrypted_data[self.SALT_SIZE + self.BLOCK_SIZE:]\n",
        "\n",
        "        key = self.derive_key(passphrase, salt)\n",
        "        cipher = AES.new(key, AES.MODE_CBC, iv)\n",
        "\n",
        "        # Attempt to decrypt. Handle potential padding errors\n",
        "        try:\n",
        "            padded_message = cipher.decrypt(ciphertext)\n",
        "            return unpad(padded_message, self.BLOCK_SIZE).decode('utf-8')\n",
        "        except ValueError:\n",
        "            print(\"Warning: Decryption failed. Possible data corruption or incorrect passphrase.\")\n",
        "            return None  # or raise a more specific exception\n",
        "\n",
        "\n",
        "    def embed_in_face_model(self, face_model, encrypted_data):\n",
        "        \"\"\"Embed encrypted data in 3D face model using geometric features\"\"\"\n",
        "        vertices = face_model['vertices'].copy()\n",
        "        faces = face_model['faces']\n",
        "        normals = face_model['normals']\n",
        "\n",
        "        # Get landmarks and importance metrics\n",
        "        landmark_vertices = self.identify_landmark_vertices(vertices)\n",
        "        importance = self.compute_vertex_importance(vertices, faces, normals)\n",
        "\n",
        "        # Convert encrypted data to bit array\n",
        "        bit_array = ''.join(format(byte, '08b') for byte in encrypted_data)\n",
        "\n",
        "        # -- Check if the message is too large --\n",
        "        if len(bit_array) > len(landmark_vertices):\n",
        "            raise ValueError(f\"Message too large for this face model. Message bits: {len(bit_array)}, Available vertices: {len(landmark_vertices)}\")\n",
        "\n",
        "        # Embed data in vertices near landmarks\n",
        "        for i, bit in enumerate(bit_array):\n",
        "            vertex_idx = landmark_vertices[i]\n",
        "\n",
        "            # Reduce scale_factor to embed less data and reduce potential corruption\n",
        "            scale_factor = 0.000005 * (1 - importance[vertex_idx])  # Reduced scale_factor\n",
        "\n",
        "            # Embed in least significant component while preserving facial features\n",
        "            vertices[vertex_idx] += (float(bit) * scale_factor * normals[vertex_idx])\n",
        "\n",
        "        face_model['vertices'] = vertices\n",
        "        return face_model\n",
        "\n",
        "    def extract_from_face_model(self, face_model, original_model, message_length):\n",
        "        \"\"\"Extract encrypted data from modified 3D face model\"\"\"\n",
        "        modified_vertices = face_model['vertices']\n",
        "        original_vertices = original_model['vertices']\n",
        "        landmark_vertices = self.identify_landmark_vertices(original_vertices)\n",
        "\n",
        "        bits = []\n",
        "        for i in range(message_length * 8):  # Iterate over the expected number of bits\n",
        "            if i >= len(landmark_vertices):\n",
        "                print(f\"Warning: Not enough landmark vertices to extract the full message. Extracted {i} bits, expected {message_length * 8} bits.\")\n",
        "                break  # Stop if we run out of landmark vertices\n",
        "            vertex_idx = landmark_vertices[i]\n",
        "            # Compare modified vertex with original\n",
        "            diff = modified_vertices[vertex_idx] - original_vertices[vertex_idx]\n",
        "            # Extract bit based on vertex displacement\n",
        "            bit = '1' if np.dot(diff, face_model['normals'][vertex_idx]) > 0 else '0'\n",
        "            bits.append(bit)\n",
        "\n",
        "        # Convert bits back to bytes\n",
        "        extracted_data = bytes(\n",
        "            int(''.join(bits[i:i + 8]), 2) for i in range(0, len(bits), 8)\n",
        "        )\n",
        "\n",
        "        return extracted_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpXnlmOzLjqq",
        "outputId": "59881b81-a341-4711-97c7-428c4077bb97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated passphrase: l*YExDuSeIiQrInqqybl5YfVVdCQYaMo\n",
            "Original message: short\n",
            "Decrypted message: short\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    # Initialize steganography system\n",
        "    stego = SecureFaceSteganography()\n",
        "\n",
        "    # Load 3D face model (example path)\n",
        "    face_model = stego.load_face_model('/content/drive/MyDrive/OutputPaper2/pjanic.obj')\n",
        "    original_model = {key: value.copy() for key, value in face_model.items()}\n",
        "\n",
        "    # Generate secure passphrase\n",
        "    passphrase = stego.generate_passphrase()\n",
        "    print(f\"Generated passphrase: {passphrase}\")\n",
        "\n",
        "    # Message to hide - Reduced length to fit within the model's capacity\n",
        "    secret_message = \"short\"\n",
        "\n",
        "    # Encrypt the message\n",
        "    encrypted_data = stego.encrypt_message(secret_message, passphrase)\n",
        "\n",
        "    # Embed encrypted data in face model\n",
        "    modified_model = stego.embed_in_face_model(face_model, encrypted_data)\n",
        "\n",
        "    # Extract and decrypt\n",
        "    extracted_data = stego.extract_from_face_model(\n",
        "        modified_model, original_model, len(encrypted_data)\n",
        "    )\n",
        "    decrypted_message = stego.decrypt_message(extracted_data, passphrase)\n",
        "\n",
        "    print(f\"Original message: {secret_message}\")\n",
        "    print(f\"Decrypted message: {decrypted_message}\")\n",
        "\n",
        "    # Save modified model\n",
        "    mesh = trimesh.Trimesh(\n",
        "        vertices=modified_model['vertices'],\n",
        "        faces=modified_model['faces']\n",
        "    )\n",
        "    mesh.export('/content/drive/MyDrive/OutputPaper2/modified_pjanic.obj')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mh6HLlBCprS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q58l2iL2prxh"
      },
      "outputs": [],
      "source": [
        "#!pip install pycryptodome\n",
        "#!pip install trimesh\n",
        "import numpy as np\n",
        "from Crypto.Cipher import AES\n",
        "from Crypto.Util.Padding import pad, unpad\n",
        "import hashlib\n",
        "import secrets\n",
        "import struct\n",
        "import trimesh\n",
        "import scipy.spatial as spatial\n",
        "\n",
        "class SecureFaceSteganography:\n",
        "    def __init__(self):\n",
        "        # ... (other code)\n",
        "        self.LANDMARK_REGIONS = {\n",
        "            'forehead': [(0.2, 0.8, 0.5), (0.8, 0.8, 0.5)],  # Wider bounding box\n",
        "            'cheeks': [(0.1, 0.5, 0.5), (0.9, 0.5, 0.5)],  # Wider bounding box\n",
        "            'jaw': [(0.2, 0.2, 0.5), (0.8, 0.2, 0.5)],  # Wider bounding box\n",
        "            'nose': [(0.4, 0.6, 0.5), (0.6, 0.6, 0.5)],  # Added nose region\n",
        "            'chin': [(0.5, 0.1, 0.5)]  #chin region\n",
        "        }\n",
        "        # Define SALT_SIZE and BLOCK_SIZE in the __init__ method\n",
        "        self.SALT_SIZE = 16  # 128 bits for salt\n",
        "        self.BLOCK_SIZE = 16 # 128 bits for block size\n",
        "\n",
        "    def load_face_model(self, file_path):\n",
        "        \"\"\"Load 3D face model and prepare it for steganography\"\"\"\n",
        "        try:\n",
        "            mesh = trimesh.load(file_path)\n",
        "            return {\n",
        "                'vertices': np.array(mesh.vertices),\n",
        "                'faces': np.array(mesh.faces),\n",
        "                'normals': np.array(mesh.vertex_normals)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error loading face model: {str(e)}\")\n",
        "\n",
        "    def identify_landmark_vertices(self, vertices, landmark_regions=None):\n",
        "        \"\"\"Identify vertices near facial landmarks for data embedding\"\"\"\n",
        "        if landmark_regions is None:\n",
        "            landmark_regions = self.LANDMARK_REGIONS\n",
        "\n",
        "        landmark_vertices = []\n",
        "        kdtree = spatial.KDTree(vertices)\n",
        "        for region, points in landmark_regions.items():\n",
        "            for point in points:\n",
        "                # Find nearest vertices to landmark points\n",
        "                # Increased k to 100 (or even higher if needed) to find more neighboring vertices\n",
        "                distances, indices = kdtree.query(point, k=1000)  # Increased k here\n",
        "                landmark_vertices.extend(indices)\n",
        "        return sorted(set(landmark_vertices))  # Remove duplicates\n",
        "\n",
        "    def compute_vertex_importance(self, vertices, faces, normals):\n",
        "        \"\"\"Compute vertex importance based on geometric features\"\"\"\n",
        "        importance = np.zeros(len(vertices))\n",
        "\n",
        "        # Calculate curvature (simplified)\n",
        "        for i, vertex in enumerate(vertices):\n",
        "            # Find connected vertices\n",
        "            connected = faces[np.any(faces == i, axis=1)]\n",
        "            connected = np.unique(connected.flatten())\n",
        "            connected = connected[connected != i]\n",
        "\n",
        "            # Calculate local curvature\n",
        "            if len(connected) > 0:\n",
        "                connected_vertices = vertices[connected]\n",
        "                mean_position = np.mean(connected_vertices, axis=0)\n",
        "                displacement = np.linalg.norm(vertex - mean_position)\n",
        "                importance[i] = displacement\n",
        "\n",
        "        return importance\n",
        "\n",
        "    def generate_passphrase(self, length=32):\n",
        "        \"\"\"Generate a cryptographically secure random passphrase\"\"\"\n",
        "        charset = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&*\"\n",
        "        return ''.join(secrets.choice(charset) for _ in range(length))\n",
        "\n",
        "    def derive_key(self, passphrase, salt):\n",
        "        \"\"\"Derive encryption key using SHA-256 with salt\"\"\"\n",
        "        key_material = hashlib.sha256()\n",
        "        key_material.update(passphrase.encode('utf-8'))\n",
        "        key_material.update(salt)\n",
        "        return key_material.digest()\n",
        "\n",
        "    def encrypt_message(self, message, passphrase):\n",
        "        \"\"\"Encrypt a message using AES-128-CBC with secure key derivation\"\"\"\n",
        "        salt = secrets.token_bytes(self.SALT_SIZE)\n",
        "        key = self.derive_key(passphrase, salt)\n",
        "        iv = secrets.token_bytes(self.BLOCK_SIZE)\n",
        "\n",
        "        cipher = AES.new(key, AES.MODE_CBC, iv)\n",
        "        padded_data = pad(message.encode('utf-8'), self.BLOCK_SIZE)\n",
        "        ciphertext = cipher.encrypt(padded_data)\n",
        "\n",
        "        return salt + iv + ciphertext\n",
        "\n",
        "    def decrypt_message(self, encrypted_data, passphrase):\n",
        "        \"\"\"Decrypt a message using AES-128-CBC\"\"\"\n",
        "        salt = encrypted_data[:self.SALT_SIZE]\n",
        "        iv = encrypted_data[self.SALT_SIZE:self.SALT_SIZE + self.BLOCK_SIZE]\n",
        "        ciphertext = encrypted_data[self.SALT_SIZE + self.BLOCK_SIZE:]\n",
        "\n",
        "        key = self.derive_key(passphrase, salt)\n",
        "        cipher = AES.new(key, AES.MODE_CBC, iv)\n",
        "\n",
        "        # Attempt to decrypt. Handle potential padding errors\n",
        "        try:\n",
        "            padded_message = cipher.decrypt(ciphertext)\n",
        "            return unpad(padded_message, self.BLOCK_SIZE).decode('utf-8')\n",
        "        except ValueError:\n",
        "            print(\"Warning: Decryption failed. Possible data corruption or incorrect passphrase.\")\n",
        "            return None  # or raise a more specific exception\n",
        "\n",
        "\n",
        "    def embed_in_face_model(self, face_model, encrypted_data):\n",
        "        \"\"\"Embed encrypted data in 3D face model using geometric features\"\"\"\n",
        "        vertices = face_model['vertices'].copy()\n",
        "        faces = face_model['faces']\n",
        "        normals = face_model['normals']\n",
        "\n",
        "        # Get landmarks and importance metrics\n",
        "        landmark_vertices = self.identify_landmark_vertices(vertices)\n",
        "        importance = self.compute_vertex_importance(vertices, faces, normals)\n",
        "\n",
        "        # Convert encrypted data to bit array\n",
        "        bit_array = ''.join(format(byte, '08b') for byte in encrypted_data)\n",
        "\n",
        "        # -- Check if the message is too large --\n",
        "        if len(bit_array) > len(landmark_vertices):\n",
        "            raise ValueError(f\"Message too large for this face model. Message bits: {len(bit_array)}, Available vertices: {len(landmark_vertices)}\")\n",
        "\n",
        "        # Embed data in vertices near landmarks\n",
        "        for i, bit in enumerate(bit_array):\n",
        "            vertex_idx = landmark_vertices[i]\n",
        "\n",
        "            # Reduce scale_factor to embed less data and reduce potential corruption\n",
        "            scale_factor = 0.000005 * (1 - importance[vertex_idx])  # Reduced scale_factor\n",
        "\n",
        "            # Embed in least significant component while preserving facial features\n",
        "            vertices[vertex_idx] += (float(bit) * scale_factor * normals[vertex_idx])\n",
        "\n",
        "        face_model['vertices'] = vertices\n",
        "        return face_model\n",
        "\n",
        "    def extract_from_face_model(self, face_model, original_model, message_length):\n",
        "        \"\"\"Extract encrypted data from modified 3D face model\"\"\"\n",
        "        modified_vertices = face_model['vertices']\n",
        "        original_vertices = original_model['vertices']\n",
        "        landmark_vertices = self.identify_landmark_vertices(original_vertices)\n",
        "\n",
        "        bits = []\n",
        "        for i in range(message_length * 8):  # Iterate over the expected number of bits\n",
        "            if i >= len(landmark_vertices):\n",
        "                print(f\"Warning: Not enough landmark vertices to extract the full message. Extracted {i} bits, expected {message_length * 8} bits.\")\n",
        "                break  # Stop if we run out of landmark vertices\n",
        "            vertex_idx = landmark_vertices[i]\n",
        "            # Compare modified vertex with original\n",
        "            diff = modified_vertices[vertex_idx] - original_vertices[vertex_idx]\n",
        "            # Extract bit based on vertex displacement\n",
        "            bit = '1' if np.dot(diff, face_model['normals'][vertex_idx]) > 0 else '0'\n",
        "            bits.append(bit)\n",
        "\n",
        "        # Convert bits back to bytes\n",
        "        extracted_data = bytes(\n",
        "            int(''.join(bits[i:i + 8]), 2) for i in range(0, len(bits), 8)\n",
        "        )\n",
        "\n",
        "        return extracted_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XuLfPxdWpvkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6da17fc-0bcd-40cf-ac61-aace2e03ddd8",
        "id": "18JVXKNCpwZS"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated passphrase: TFWlxnNM*pqqCjLZgu^&6C$4YcYWGMk8\n",
            "Original message: short Message\n",
            "Decrypted message: short Message\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    # Initialize steganography system\n",
        "    stego = SecureFaceSteganography()\n",
        "\n",
        "    # Load 3D face model (example path)\n",
        "    face_model = stego.load_face_model('/content/drive/MyDrive/OutputPaper2/pjanic.obj')\n",
        "    original_model = {key: value.copy() for key, value in face_model.items()}\n",
        "\n",
        "    # Generate secure passphrase\n",
        "    passphrase = stego.generate_passphrase()\n",
        "    print(f\"Generated passphrase: {passphrase}\")\n",
        "\n",
        "    # Message to hide - Reduced length to fit within the model's capacity\n",
        "    secret_message = \"short Message\"\n",
        "\n",
        "    # Encrypt the message\n",
        "    encrypted_data = stego.encrypt_message(secret_message, passphrase)\n",
        "\n",
        "    # Embed encrypted data in face model\n",
        "    modified_model = stego.embed_in_face_model(face_model, encrypted_data)\n",
        "\n",
        "    # Extract and decrypt\n",
        "    extracted_data = stego.extract_from_face_model(\n",
        "        modified_model, original_model, len(encrypted_data)\n",
        "    )\n",
        "    decrypted_message = stego.decrypt_message(extracted_data, passphrase)\n",
        "\n",
        "    print(f\"Original message: {secret_message}\")\n",
        "    print(f\"Decrypted message: {decrypted_message}\")\n",
        "\n",
        "    # Save modified model\n",
        "    mesh = trimesh.Trimesh(\n",
        "        vertices=modified_model['vertices'],\n",
        "        faces=modified_model['faces']\n",
        "    )\n",
        "    mesh.export('/content/drive/MyDrive/OutputPaper2/modified_pjanic.obj')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ggswZNE9Bj4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import trimesh\n",
        "from scipy.spatial.distance import directed_hausdorff\n",
        "\n",
        "# Load the models\n",
        "original_mesh = trimesh.load('/content/drive/MyDrive/OutputPaper2/modified_pjanic.obj')\n",
        "stego_mesh = trimesh.load('/content/drive/MyDrive/OutputPaper2/pjanic.obj')\n",
        "\n",
        "# Calculate surface area\n",
        "original_surface_area = original_mesh.area\n",
        "stego_surface_area = stego_mesh.area\n",
        "\n",
        "# Calculate volume\n",
        "original_volume = original_mesh.volume\n",
        "stego_volume = stego_mesh.volume\n",
        "\n",
        "# Calculate Hausdorff distance\n",
        "hausdorff_distance = directed_hausdorff(original_mesh.vertices, stego_mesh.vertices)[0]\n",
        "\n",
        "# Print the results\n",
        "print(\"Original Surface Area:\", original_surface_area)\n",
        "print(\"Stego Surface Area:\", stego_surface_area)\n",
        "print(\"Original Volume:\", original_volume)\n",
        "print(\"Stego Volume:\", stego_volume)\n",
        "print(\"Hausdorff Distance:\", hausdorff_distance)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF_rDy5UAZTa",
        "outputId": "6d14af6d-756b-4a53-d495-5685150d135b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Surface Area: 58.79708420156814\n",
            "Stego Surface Area: 58.79708350578467\n",
            "Original Volume: 28.31652861618301\n",
            "Stego Volume: 28.316527674660872\n",
            "Hausdorff Distance: 5.004997502504824e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install 'pyglet<2'\n",
        "#!apt-get install -y libglu1-mesa-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCvHsjMkDQzU",
        "outputId": "650b491b-3f82-4a2f-f696-39bca512f4d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libgl-dev libglu1-mesa libglx-dev\n",
            "The following NEW packages will be installed:\n",
            "  libgl-dev libglu1-mesa libglu1-mesa-dev libglx-dev\n",
            "0 upgraded, 4 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 492 kB of archives.\n",
            "After this operation, 2,830 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
            "Fetched 492 kB in 0s (4,259 kB/s)\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
            "Preparing to unpack .../libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "source": [
        "#!pip install pyglet\n",
        "#!pip install pyglet<2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import trimesh\n",
        "from scipy.stats import wasserstein_distance\n",
        "from skimage.metrics import structural_similarity\n",
        "import math\n",
        "from scipy.spatial import KDTree\n",
        "import os\n",
        "\n",
        "class Stego3DEvaluator:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the 3D steganography evaluator\"\"\"\n",
        "        self.metrics = {}\n",
        "\n",
        "    def preprocess_models(self, original_mesh, stego_mesh):\n",
        "        \"\"\"Preprocess and align models to ensure compatibility\"\"\"\n",
        "        # Center both meshes\n",
        "        original_mesh.vertices -= original_mesh.vertices.mean(axis=0)\n",
        "        stego_mesh.vertices -= stego_mesh.vertices.mean(axis=0)\n",
        "\n",
        "        # Scale to unit cube\n",
        "        original_scale = np.max(np.abs(original_mesh.vertices))\n",
        "        stego_scale = np.max(np.abs(stego_mesh.vertices))\n",
        "\n",
        "        original_mesh.vertices /= original_scale\n",
        "        stego_mesh.vertices /= stego_scale\n",
        "\n",
        "        return original_mesh, stego_mesh\n",
        "\n",
        "    def align_vertices(self, original_vertices, stego_vertices):\n",
        "        \"\"\"Align vertices between models using nearest neighbor matching\"\"\"\n",
        "        # Build KD-tree for faster nearest neighbor search\n",
        "        tree = KDTree(original_vertices)\n",
        "\n",
        "        # Find nearest neighbors for each stego vertex\n",
        "        distances, indices = tree.query(stego_vertices)\n",
        "\n",
        "        # Create aligned vertex arrays\n",
        "        aligned_original = original_vertices[indices]\n",
        "        aligned_stego = stego_vertices\n",
        "\n",
        "        return aligned_original, aligned_stego, distances\n",
        "\n",
        "    def load_models(self, original_path, stego_path, align=True):\n",
        "        \"\"\"Load and preprocess original and stego 3D models\"\"\"\n",
        "        try:\n",
        "            # Load meshes\n",
        "            original_mesh = trimesh.load(original_path)\n",
        "            stego_mesh = trimesh.load(stego_path)\n",
        "\n",
        "            print(f\"Original vertices: {len(original_mesh.vertices)}\")\n",
        "            print(f\"Stego vertices: {len(stego_mesh.vertices)}\")\n",
        "\n",
        "            # Preprocess meshes\n",
        "            original_mesh, stego_mesh = self.preprocess_models(original_mesh, stego_mesh)\n",
        "\n",
        "            if align:\n",
        "                # Align vertices\n",
        "                self.original_vertices, self.stego_vertices, distances = self.align_vertices(\n",
        "                    original_mesh.vertices,\n",
        "                    stego_mesh.vertices\n",
        "                )\n",
        "\n",
        "                # Print alignment statistics\n",
        "                print(f\"\\nAlignment Statistics:\")\n",
        "                print(f\"Mean distance: {np.mean(distances):.6f}\")\n",
        "                print(f\"Max distance: {np.max(distances):.6f}\")\n",
        "                print(f\"Aligned vertices: {len(self.original_vertices)}\")\n",
        "            else:\n",
        "                if len(original_mesh.vertices) != len(stego_mesh.vertices):\n",
        "                    raise ValueError(\"Models have different number of vertices and alignment is disabled\")\n",
        "                self.original_vertices = original_mesh.vertices\n",
        "                self.stego_vertices = stego_mesh.vertices\n",
        "\n",
        "            self.original_mesh = original_mesh\n",
        "            self.stego_mesh = stego_mesh\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading models: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def calculate_vertex_error_map(self):\n",
        "        \"\"\"Calculate and visualize vertex-wise errors\"\"\"\n",
        "        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n",
        "        return errors\n",
        "\n",
        "\n",
        "\n",
        "    def calculate_psnr(self):\n",
        "        \"\"\"Calculate Peak Signal-to-Noise Ratio\"\"\"\n",
        "        mse = np.mean((self.original_vertices - self.stego_vertices) ** 2)\n",
        "        if mse == 0:\n",
        "            return float('inf')\n",
        "\n",
        "        max_val = np.max(self.original_vertices) - np.min(self.original_vertices)\n",
        "        psnr = 20 * math.log10(max_val / math.sqrt(mse))\n",
        "        self.metrics['PSNR'] = psnr\n",
        "        return psnr\n",
        "\n",
        "    def calculate_ssim(self):\n",
        "        \"\"\"Calculate Structural Similarity Index\"\"\"\n",
        "        orig_reshaped = self.original_vertices.reshape(-1, 3)\n",
        "        stego_reshaped = self.stego_vertices.reshape(-1, 3)\n",
        "\n",
        "        ssim_scores = []\n",
        "        for i in range(3):\n",
        "            score = structural_similarity(\n",
        "                orig_reshaped[:, i],\n",
        "                stego_reshaped[:, i],\n",
        "                data_range=np.max(orig_reshaped[:, i]) - np.min(orig_reshaped[:, i])\n",
        "            )\n",
        "            ssim_scores.append(score)\n",
        "\n",
        "        ssim = np.mean(ssim_scores)\n",
        "        self.metrics['SSIM'] = ssim\n",
        "        return ssim\n",
        "\n",
        "    def calculate_mse(self):\n",
        "        \"\"\"Calculate Mean Squared Error\"\"\"\n",
        "        mse = mean_squared_error(self.original_vertices, self.stego_vertices)\n",
        "        self.metrics['MSE'] = mse\n",
        "        return mse\n",
        "\n",
        "    def calculate_rmse(self):\n",
        "        \"\"\"Calculate Root Mean Squared Error\"\"\"\n",
        "        rmse = np.sqrt(self.calculate_mse())\n",
        "        self.metrics['RMSE'] = rmse\n",
        "        return rmse\n",
        "\n",
        "    def calculate_ber(self, threshold=1e-6):\n",
        "        \"\"\"Calculate Bit Error Rate\"\"\"\n",
        "        differences = np.abs(self.original_vertices - self.stego_vertices)\n",
        "        binary_orig = (self.original_vertices > threshold).astype(int)\n",
        "        binary_stego = (self.stego_vertices > threshold).astype(int)\n",
        "\n",
        "        total_bits = np.prod(binary_orig.shape)\n",
        "        error_bits = np.sum(binary_orig != binary_stego)\n",
        "\n",
        "        ber = error_bits / total_bits\n",
        "        self.metrics['BER'] = ber\n",
        "        return ber\n",
        "\n",
        "    def calculate_hausdorff_distance(self):\n",
        "        \"\"\"Calculate Hausdorff distance between original and stego models\"\"\"\n",
        "        def directed_hausdorff(source, target):\n",
        "            tree = KDTree(target)\n",
        "            distances, _ = tree.query(source)\n",
        "            return np.max(distances)\n",
        "\n",
        "        forward = directed_hausdorff(self.original_vertices, self.stego_vertices)\n",
        "        backward = directed_hausdorff(self.stego_vertices, self.original_vertices)\n",
        "\n",
        "        hausdorff = max(forward, backward)\n",
        "        self.metrics['Hausdorff'] = hausdorff\n",
        "        return hausdorff\n",
        "\n",
        "    def calculate_histogram_similarity(self, bins=50):\n",
        "        \"\"\"Calculate histogram similarity using Wasserstein distance\"\"\"\n",
        "        distances = []\n",
        "\n",
        "        for i in range(3):\n",
        "            hist_orig, _ = np.histogram(self.original_vertices[:, i], bins=bins, density=True)\n",
        "            hist_stego, _ = np.histogram(self.stego_vertices[:, i], bins=bins, density=True)\n",
        "\n",
        "            distance = wasserstein_distance(hist_orig, hist_stego)\n",
        "            distances.append(distance)\n",
        "\n",
        "        hist_similarity = 1 / (1 + np.mean(distances))\n",
        "        self.metrics['Histogram_Similarity'] = hist_similarity\n",
        "        return hist_similarity\n",
        "\n",
        "    def plot_histograms(self, save_path=None):\n",
        "        \"\"\"Plot histograms of original and stego models\"\"\"\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        coords = ['X', 'Y', 'Z']\n",
        "\n",
        "        for i, (ax, coord) in enumerate(zip(axes, coords)):\n",
        "            ax.hist(self.original_vertices[:, i], bins=50, alpha=0.5, label='Original', density=True)\n",
        "            ax.hist(self.stego_vertices[:, i], bins=50, alpha=0.5, label='Stego', density=True)\n",
        "            ax.set_title(f'{coord} Coordinate Distribution')\n",
        "            ax.set_xlabel(f'{coord} Value')\n",
        "            ax.set_ylabel('Density')\n",
        "            ax.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        if save_path:\n",
        "            plt.savefig(save_path)\n",
        "            plt.close()\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "    def plot_error_distribution(self, save_path=None):\n",
        "        \"\"\"Plot the distribution of geometric errors\"\"\"\n",
        "        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.hist(errors, bins=50, density=True)\n",
        "        plt.title('Geometric Error Distribution')\n",
        "        plt.xlabel('Error Magnitude')\n",
        "        plt.ylabel('Density')\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path)\n",
        "            plt.close()\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "    def evaluate_all(self, plot=True, save_plots=False):\n",
        "        \"\"\"Calculate all metrics and optionally generate plots\"\"\"\n",
        "        metrics = {\n",
        "            'PSNR': self.calculate_psnr(),\n",
        "            'SSIM': self.calculate_ssim(),\n",
        "            'MSE': self.calculate_mse(),\n",
        "            'RMSE': self.calculate_rmse(),\n",
        "            'BER': self.calculate_ber(),\n",
        "            'Hausdorff': self.calculate_hausdorff_distance(),\n",
        "            'Histogram_Similarity': self.calculate_histogram_similarity()\n",
        "        }\n",
        "\n",
        "        if plot:\n",
        "            self.plot_histograms(save_path='histograms.png' if save_plots else None)\n",
        "            self.plot_error_distribution(save_path='error_distribution.png' if save_plots else None)\n",
        "            #self.visualize_error_map(save_path='error_map.png' if save_plots else None)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "def main():\n",
        "    # Initialize evaluator\n",
        "    evaluator = Stego3DEvaluator()\n",
        "\n",
        "    # Load and align models\n",
        "    if not evaluator.load_models('/content/drive/MyDrive/OutputPaper2/modified_pjanic.obj', '/content/drive/MyDrive/OutputPaper2/pjanic.obj', align=True):\n",
        "        return\n",
        "\n",
        "    # Perform evaluation\n",
        "    metrics = evaluator.evaluate_all(plot=True, save_plots=True)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nEvaluation Results:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value:.6f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL7-3rJnCU4a",
        "outputId": "617e791b-1e76-466f-be5d-c077d19549cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original vertices: 215999\n",
            "Stego vertices: 220141\n",
            "\n",
            "Alignment Statistics:\n",
            "Mean distance: 0.000911\n",
            "Max distance: 0.000959\n",
            "Aligned vertices: 220141\n",
            "\n",
            "Evaluation Results:\n",
            "PSNR: 69.809654\n",
            "SSIM: 0.999811\n",
            "MSE: 0.000000\n",
            "RMSE: 0.000526\n",
            "BER: 0.000486\n",
            "Hausdorff: 0.000959\n",
            "Histogram_Similarity: 0.999544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-DVHlLMSI1fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#!pip install pyglet\n",
        "#!pip install pyglet<2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import trimesh\n",
        "from scipy.stats import wasserstein_distance\n",
        "from skimage.metrics import structural_similarity\n",
        "import math\n",
        "from scipy.spatial import KDTree\n",
        "import os\n",
        "\n",
        "class Stego3DEvaluator:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the 3D steganography evaluator\"\"\"\n",
        "        self.metrics = {}\n",
        "\n",
        "    def preprocess_models(self, original_mesh, stego_mesh):\n",
        "        \"\"\"Preprocess and align models to ensure compatibility\"\"\"\n",
        "        # Center both meshes\n",
        "        original_mesh.vertices -= original_mesh.vertices.mean(axis=0)\n",
        "        stego_mesh.vertices -= stego_mesh.vertices.mean(axis=0)\n",
        "\n",
        "        # Scale to unit cube\n",
        "        original_scale = np.max(np.abs(original_mesh.vertices))\n",
        "        stego_scale = np.max(np.abs(stego_mesh.vertices))\n",
        "\n",
        "        original_mesh.vertices /= original_scale\n",
        "        stego_mesh.vertices /= stego_scale\n",
        "\n",
        "        return original_mesh, stego_mesh\n",
        "\n",
        "    def align_vertices(self, original_vertices, stego_vertices):\n",
        "        \"\"\"Align vertices between models using nearest neighbor matching\"\"\"\n",
        "        # Build KD-tree for faster nearest neighbor search\n",
        "        tree = KDTree(original_vertices)\n",
        "\n",
        "        # Find nearest neighbors for each stego vertex\n",
        "        distances, indices = tree.query(stego_vertices)\n",
        "\n",
        "        # Create aligned vertex arrays\n",
        "        aligned_original = original_vertices[indices]\n",
        "        aligned_stego = stego_vertices\n",
        "\n",
        "        return aligned_original, aligned_stego, distances\n",
        "\n",
        "    def load_models(self, original_path, stego_path, align=True):\n",
        "        \"\"\"Load and preprocess original and stego 3D models\"\"\"\n",
        "        try:\n",
        "            # Load meshes\n",
        "            original_mesh = trimesh.load(original_path)\n",
        "            stego_mesh = trimesh.load(stego_path)\n",
        "\n",
        "            print(f\"Original vertices: {len(original_mesh.vertices)}\")\n",
        "            print(f\"Stego vertices: {len(stego_mesh.vertices)}\")\n",
        "\n",
        "            # Preprocess meshes\n",
        "            original_mesh, stego_mesh = self.preprocess_models(original_mesh, stego_mesh)\n",
        "\n",
        "            if align:\n",
        "                # Align vertices\n",
        "                self.original_vertices, self.stego_vertices, distances = self.align_vertices(\n",
        "                    original_mesh.vertices,\n",
        "                    stego_mesh.vertices\n",
        "                )\n",
        "\n",
        "                # Print alignment statistics\n",
        "                print(f\"\\nAlignment Statistics:\")\n",
        "                print(f\"Mean distance: {np.mean(distances):.6f}\")\n",
        "                print(f\"Max distance: {np.max(distances):.6f}\")\n",
        "                print(f\"Aligned vertices: {len(self.original_vertices)}\")\n",
        "            else:\n",
        "                if len(original_mesh.vertices) != len(stego_mesh.vertices):\n",
        "                    raise ValueError(\"Models have different number of vertices and alignment is disabled\")\n",
        "                self.original_vertices = original_mesh.vertices\n",
        "                self.stego_vertices = stego_mesh.vertices\n",
        "\n",
        "            self.original_mesh = original_mesh\n",
        "            self.stego_mesh = stego_mesh\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading models: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def calculate_vertex_error_map(self):\n",
        "        \"\"\"Calculate and visualize vertex-wise errors\"\"\"\n",
        "        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n",
        "        return errors\n",
        "\n",
        "\n",
        "\n",
        "    def calculate_psnr(self):\n",
        "        \"\"\"Calculate Peak Signal-to-Noise Ratio\"\"\"\n",
        "        mse = np.mean((self.original_vertices - self.stego_vertices) ** 2)\n",
        "        if mse == 0:\n",
        "            return float('inf')\n",
        "\n",
        "        max_val = np.max(self.original_vertices) - np.min(self.original_vertices)\n",
        "        psnr = 20 * math.log10(max_val / math.sqrt(mse))\n",
        "        self.metrics['PSNR'] = psnr\n",
        "        return psnr\n",
        "\n",
        "    def calculate_ssim(self):\n",
        "        \"\"\"Calculate Structural Similarity Index\"\"\"\n",
        "        orig_reshaped = self.original_vertices.reshape(-1, 3)\n",
        "        stego_reshaped = self.stego_vertices.reshape(-1, 3)\n",
        "\n",
        "        ssim_scores = []\n",
        "        for i in range(3):\n",
        "            score = structural_similarity(\n",
        "                orig_reshaped[:, i],\n",
        "                stego_reshaped[:, i],\n",
        "                data_range=np.max(orig_reshaped[:, i]) - np.min(orig_reshaped[:, i])\n",
        "            )\n",
        "            ssim_scores.append(score)\n",
        "\n",
        "        ssim = np.mean(ssim_scores)\n",
        "        self.metrics['SSIM'] = ssim\n",
        "        return ssim\n",
        "\n",
        "    def calculate_mse(self):\n",
        "        \"\"\"Calculate Mean Squared Error\"\"\"\n",
        "        mse = mean_squared_error(self.original_vertices, self.stego_vertices)\n",
        "        self.metrics['MSE'] = mse\n",
        "        return mse\n",
        "\n",
        "    def calculate_rmse(self):\n",
        "        \"\"\"Calculate Root Mean Squared Error\"\"\"\n",
        "        rmse = np.sqrt(self.calculate_mse())\n",
        "        self.metrics['RMSE'] = rmse\n",
        "        return rmse\n",
        "\n",
        "    def calculate_ber(self, threshold=1e-6):\n",
        "        \"\"\"Calculate Bit Error Rate\"\"\"\n",
        "        differences = np.abs(self.original_vertices - self.stego_vertices)\n",
        "        binary_orig = (self.original_vertices > threshold).astype(int)\n",
        "        binary_stego = (self.stego_vertices > threshold).astype(int)\n",
        "\n",
        "        total_bits = np.prod(binary_orig.shape)\n",
        "        error_bits = np.sum(binary_orig != binary_stego)\n",
        "\n",
        "        ber = error_bits / total_bits\n",
        "        self.metrics['BER'] = ber\n",
        "        return ber\n",
        "\n",
        "    def calculate_hausdorff_distance(self):\n",
        "        \"\"\"Calculate Hausdorff distance between original and stego models\"\"\"\n",
        "        def directed_hausdorff(source, target):\n",
        "            tree = KDTree(target)\n",
        "            distances, _ = tree.query(source)\n",
        "            return np.max(distances)\n",
        "\n",
        "        forward = directed_hausdorff(self.original_vertices, self.stego_vertices)\n",
        "        backward = directed_hausdorff(self.stego_vertices, self.original_vertices)\n",
        "\n",
        "        hausdorff = max(forward, backward)\n",
        "        self.metrics['Hausdorff'] = hausdorff\n",
        "        return hausdorff\n",
        "\n",
        "    def calculate_histogram_similarity(self, bins=50):\n",
        "        \"\"\"Calculate histogram similarity using Wasserstein distance\"\"\"\n",
        "        distances = []\n",
        "\n",
        "        for i in range(3):\n",
        "            hist_orig, _ = np.histogram(self.original_vertices[:, i], bins=bins, density=True)\n",
        "            hist_stego, _ = np.histogram(self.stego_vertices[:, i], bins=bins, density=True)\n",
        "\n",
        "            distance = wasserstein_distance(hist_orig, hist_stego)\n",
        "            distances.append(distance)\n",
        "\n",
        "        hist_similarity = 1 / (1 + np.mean(distances))\n",
        "        self.metrics['Histogram_Similarity'] = hist_similarity\n",
        "        return hist_similarity\n",
        "\n",
        "    def plot_histograms(self, save_path=None):\n",
        "        \"\"\"Plot histograms of original and stego models\"\"\"\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        coords = ['X', 'Y', 'Z']\n",
        "\n",
        "        for i, (ax, coord) in enumerate(zip(axes, coords)):\n",
        "            ax.hist(self.original_vertices[:, i], bins=50, alpha=0.5, label='Original', density=True)\n",
        "            ax.hist(self.stego_vertices[:, i], bins=50, alpha=0.5, label='Stego', density=True)\n",
        "            ax.set_title(f'{coord} Coordinate Distribution')\n",
        "            ax.set_xlabel(f'{coord} Value')\n",
        "            ax.set_ylabel('Density')\n",
        "            ax.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        if save_path:\n",
        "            plt.savefig(save_path)\n",
        "            plt.close()\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "    def plot_error_distribution(self, save_path=None):\n",
        "        \"\"\"Plot the distribution of geometric errors\"\"\"\n",
        "        errors = np.linalg.norm(self.original_vertices - self.stego_vertices, axis=1)\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.hist(errors, bins=50, density=True)\n",
        "        plt.title('Geometric Error Distribution')\n",
        "        plt.xlabel('Error Magnitude')\n",
        "        plt.ylabel('Density')\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path)\n",
        "            plt.close()\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "    def evaluate_all(self, plot=True, save_plots=False):\n",
        "        \"\"\"Calculate all metrics and optionally generate plots\"\"\"\n",
        "        metrics = {\n",
        "            'PSNR': self.calculate_psnr(),\n",
        "            'SSIM': self.calculate_ssim(),\n",
        "            'MSE': self.calculate_mse(),\n",
        "            'RMSE': self.calculate_rmse(),\n",
        "            'BER': self.calculate_ber(),\n",
        "            'Hausdorff': self.calculate_hausdorff_distance(),\n",
        "            'Histogram_Similarity': self.calculate_histogram_similarity()\n",
        "        }\n",
        "\n",
        "        if plot:\n",
        "            self.plot_histograms(save_path='histograms.png' if save_plots else None)\n",
        "            self.plot_error_distribution(save_path='error_distribution.png' if save_plots else None)\n",
        "            #self.visualize_error_map(save_path='error_map.png' if save_plots else None)\n",
        "\n",
        "        return metrics\n",
        "    def generate_report(self, output_path='/content/drive/MyDrive/OutputPaper2/evaluation_report.txt'):\n",
        "        \"\"\"Generate a detailed evaluation report\"\"\"\n",
        "        with open(output_path, 'w') as f:\n",
        "            f.write(\"3D Steganography Evaluation Report\\n\")\n",
        "            f.write(\"=================================\\n\\n\")\n",
        "\n",
        "            # Model information\n",
        "            f.write(\"Model Information:\\n\")\n",
        "            f.write(f\"Number of vertices: {len(self.original_vertices)}\\n\")\n",
        "            f.write(f\"Number of faces: {len(self.original_mesh.faces)}\\n\\n\")\n",
        "\n",
        "            # Metrics\n",
        "            f.write(\"Quality Metrics:\\n\")\n",
        "            for metric, value in self.metrics.items():\n",
        "                f.write(f\"{metric}: {value:.6f}\\n\")\n",
        "\n",
        "            f.write(\"\\nInterpretation:\\n\")\n",
        "            f.write(\"- PSNR > 30 dB typically indicates good quality\\n\")\n",
        "            f.write(\"- SSIM closer to 1 indicates better structural preservation\\n\")\n",
        "            f.write(\"- Lower MSE and RMSE values indicate better similarity\\n\")\n",
        "            f.write(\"- Lower BER indicates better steganographic accuracy\\n\")\n",
        "            f.write(\"- Histogram similarity closer to 1 indicates better statistical imperceptibility\\n\")\n",
        "\n",
        "def main():\n",
        "    # Initialize evaluator\n",
        "    evaluator = Stego3DEvaluator()\n",
        "\n",
        "    # Load and align models\n",
        "    if not evaluator.load_models('/content/drive/MyDrive/OutputPaper2/modified_pjanic.obj', '/content/drive/MyDrive/OutputPaper2/pjanic.obj', align=True):\n",
        "        return\n",
        "\n",
        "    # Perform evaluation\n",
        "    metrics = evaluator.evaluate_all(plot=True, save_plots=True)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nEvaluation Results:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value:.6f}\")\n",
        "    evaluator.generate_report()\n",
        "    print(\"\\nDetailed report saved to '/content/drive/MyDrive/OutputPaper2/evaluation_report.txt'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045bd0ec-19b8-4056-c163-7ae39a57d969",
        "id": "w8vZDDo0I3TB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original vertices: 215999\n",
            "Stego vertices: 220141\n",
            "\n",
            "Alignment Statistics:\n",
            "Mean distance: 0.000911\n",
            "Max distance: 0.000959\n",
            "Aligned vertices: 220141\n",
            "\n",
            "Evaluation Results:\n",
            "PSNR: 69.809654\n",
            "SSIM: 0.999811\n",
            "MSE: 0.000000\n",
            "RMSE: 0.000526\n",
            "BER: 0.000486\n",
            "Hausdorff: 0.000959\n",
            "Histogram_Similarity: 0.999544\n",
            "\n",
            "Detailed report saved to '/content/drive/MyDrive/OutputPaper2/evaluation_report.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FSzEDnYpGyQa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}